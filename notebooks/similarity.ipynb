{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2687e2d6c5e49bd9843e69be3cb9fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llmin.similarity import sim_matrix\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "target_model = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    target_model,\n",
    "    device_map = \"cuda\",\n",
    "    torch_dtype = torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.layers.0.self_attn.q_proj',\n",
       " 'model.layers.0.self_attn.k_proj',\n",
       " 'model.layers.0.self_attn.v_proj',\n",
       " 'model.layers.0.self_attn.o_proj',\n",
       " 'model.layers.0.mlp.gate_proj',\n",
       " 'model.layers.0.mlp.up_proj',\n",
       " 'model.layers.0.mlp.down_proj',\n",
       " 'model.layers.1.self_attn.q_proj',\n",
       " 'model.layers.1.self_attn.k_proj',\n",
       " 'model.layers.1.self_attn.v_proj',\n",
       " 'model.layers.1.self_attn.o_proj',\n",
       " 'model.layers.1.mlp.gate_proj',\n",
       " 'model.layers.1.mlp.up_proj',\n",
       " 'model.layers.1.mlp.down_proj',\n",
       " 'model.layers.2.self_attn.q_proj',\n",
       " 'model.layers.2.self_attn.k_proj',\n",
       " 'model.layers.2.self_attn.v_proj',\n",
       " 'model.layers.2.self_attn.o_proj',\n",
       " 'model.layers.2.mlp.gate_proj',\n",
       " 'model.layers.2.mlp.up_proj',\n",
       " 'model.layers.2.mlp.down_proj',\n",
       " 'model.layers.3.self_attn.q_proj',\n",
       " 'model.layers.3.self_attn.k_proj',\n",
       " 'model.layers.3.self_attn.v_proj',\n",
       " 'model.layers.3.self_attn.o_proj',\n",
       " 'model.layers.3.mlp.gate_proj',\n",
       " 'model.layers.3.mlp.up_proj',\n",
       " 'model.layers.3.mlp.down_proj',\n",
       " 'model.layers.4.self_attn.q_proj',\n",
       " 'model.layers.4.self_attn.k_proj',\n",
       " 'model.layers.4.self_attn.v_proj',\n",
       " 'model.layers.4.self_attn.o_proj',\n",
       " 'model.layers.4.mlp.gate_proj',\n",
       " 'model.layers.4.mlp.up_proj',\n",
       " 'model.layers.4.mlp.down_proj',\n",
       " 'model.layers.5.self_attn.q_proj',\n",
       " 'model.layers.5.self_attn.k_proj',\n",
       " 'model.layers.5.self_attn.v_proj',\n",
       " 'model.layers.5.self_attn.o_proj',\n",
       " 'model.layers.5.mlp.gate_proj',\n",
       " 'model.layers.5.mlp.up_proj',\n",
       " 'model.layers.5.mlp.down_proj',\n",
       " 'model.layers.6.self_attn.q_proj',\n",
       " 'model.layers.6.self_attn.k_proj',\n",
       " 'model.layers.6.self_attn.v_proj',\n",
       " 'model.layers.6.self_attn.o_proj',\n",
       " 'model.layers.6.mlp.gate_proj',\n",
       " 'model.layers.6.mlp.up_proj',\n",
       " 'model.layers.6.mlp.down_proj',\n",
       " 'model.layers.7.self_attn.q_proj',\n",
       " 'model.layers.7.self_attn.k_proj',\n",
       " 'model.layers.7.self_attn.v_proj',\n",
       " 'model.layers.7.self_attn.o_proj',\n",
       " 'model.layers.7.mlp.gate_proj',\n",
       " 'model.layers.7.mlp.up_proj',\n",
       " 'model.layers.7.mlp.down_proj',\n",
       " 'model.layers.8.self_attn.q_proj',\n",
       " 'model.layers.8.self_attn.k_proj',\n",
       " 'model.layers.8.self_attn.v_proj',\n",
       " 'model.layers.8.self_attn.o_proj',\n",
       " 'model.layers.8.mlp.gate_proj',\n",
       " 'model.layers.8.mlp.up_proj',\n",
       " 'model.layers.8.mlp.down_proj',\n",
       " 'model.layers.9.self_attn.q_proj',\n",
       " 'model.layers.9.self_attn.k_proj',\n",
       " 'model.layers.9.self_attn.v_proj',\n",
       " 'model.layers.9.self_attn.o_proj',\n",
       " 'model.layers.9.mlp.gate_proj',\n",
       " 'model.layers.9.mlp.up_proj',\n",
       " 'model.layers.9.mlp.down_proj',\n",
       " 'model.layers.10.self_attn.q_proj',\n",
       " 'model.layers.10.self_attn.k_proj',\n",
       " 'model.layers.10.self_attn.v_proj',\n",
       " 'model.layers.10.self_attn.o_proj',\n",
       " 'model.layers.10.mlp.gate_proj',\n",
       " 'model.layers.10.mlp.up_proj',\n",
       " 'model.layers.10.mlp.down_proj',\n",
       " 'model.layers.11.self_attn.q_proj',\n",
       " 'model.layers.11.self_attn.k_proj',\n",
       " 'model.layers.11.self_attn.v_proj',\n",
       " 'model.layers.11.self_attn.o_proj',\n",
       " 'model.layers.11.mlp.gate_proj',\n",
       " 'model.layers.11.mlp.up_proj',\n",
       " 'model.layers.11.mlp.down_proj',\n",
       " 'model.layers.12.self_attn.q_proj',\n",
       " 'model.layers.12.self_attn.k_proj',\n",
       " 'model.layers.12.self_attn.v_proj',\n",
       " 'model.layers.12.self_attn.o_proj',\n",
       " 'model.layers.12.mlp.gate_proj',\n",
       " 'model.layers.12.mlp.up_proj',\n",
       " 'model.layers.12.mlp.down_proj',\n",
       " 'model.layers.13.self_attn.q_proj',\n",
       " 'model.layers.13.self_attn.k_proj',\n",
       " 'model.layers.13.self_attn.v_proj',\n",
       " 'model.layers.13.self_attn.o_proj',\n",
       " 'model.layers.13.mlp.gate_proj',\n",
       " 'model.layers.13.mlp.up_proj',\n",
       " 'model.layers.13.mlp.down_proj',\n",
       " 'model.layers.14.self_attn.q_proj',\n",
       " 'model.layers.14.self_attn.k_proj',\n",
       " 'model.layers.14.self_attn.v_proj',\n",
       " 'model.layers.14.self_attn.o_proj',\n",
       " 'model.layers.14.mlp.gate_proj',\n",
       " 'model.layers.14.mlp.up_proj',\n",
       " 'model.layers.14.mlp.down_proj',\n",
       " 'model.layers.15.self_attn.q_proj',\n",
       " 'model.layers.15.self_attn.k_proj',\n",
       " 'model.layers.15.self_attn.v_proj',\n",
       " 'model.layers.15.self_attn.o_proj',\n",
       " 'model.layers.15.mlp.gate_proj',\n",
       " 'model.layers.15.mlp.up_proj',\n",
       " 'model.layers.15.mlp.down_proj',\n",
       " 'model.layers.16.self_attn.q_proj',\n",
       " 'model.layers.16.self_attn.k_proj',\n",
       " 'model.layers.16.self_attn.v_proj',\n",
       " 'model.layers.16.self_attn.o_proj',\n",
       " 'model.layers.16.mlp.gate_proj',\n",
       " 'model.layers.16.mlp.up_proj',\n",
       " 'model.layers.16.mlp.down_proj',\n",
       " 'model.layers.17.self_attn.q_proj',\n",
       " 'model.layers.17.self_attn.k_proj',\n",
       " 'model.layers.17.self_attn.v_proj',\n",
       " 'model.layers.17.self_attn.o_proj',\n",
       " 'model.layers.17.mlp.gate_proj',\n",
       " 'model.layers.17.mlp.up_proj',\n",
       " 'model.layers.17.mlp.down_proj',\n",
       " 'model.layers.18.self_attn.q_proj',\n",
       " 'model.layers.18.self_attn.k_proj',\n",
       " 'model.layers.18.self_attn.v_proj',\n",
       " 'model.layers.18.self_attn.o_proj',\n",
       " 'model.layers.18.mlp.gate_proj',\n",
       " 'model.layers.18.mlp.up_proj',\n",
       " 'model.layers.18.mlp.down_proj',\n",
       " 'model.layers.19.self_attn.q_proj',\n",
       " 'model.layers.19.self_attn.k_proj',\n",
       " 'model.layers.19.self_attn.v_proj',\n",
       " 'model.layers.19.self_attn.o_proj',\n",
       " 'model.layers.19.mlp.gate_proj',\n",
       " 'model.layers.19.mlp.up_proj',\n",
       " 'model.layers.19.mlp.down_proj',\n",
       " 'model.layers.20.self_attn.q_proj',\n",
       " 'model.layers.20.self_attn.k_proj',\n",
       " 'model.layers.20.self_attn.v_proj',\n",
       " 'model.layers.20.self_attn.o_proj',\n",
       " 'model.layers.20.mlp.gate_proj',\n",
       " 'model.layers.20.mlp.up_proj',\n",
       " 'model.layers.20.mlp.down_proj',\n",
       " 'model.layers.21.self_attn.q_proj',\n",
       " 'model.layers.21.self_attn.k_proj',\n",
       " 'model.layers.21.self_attn.v_proj',\n",
       " 'model.layers.21.self_attn.o_proj',\n",
       " 'model.layers.21.mlp.gate_proj',\n",
       " 'model.layers.21.mlp.up_proj',\n",
       " 'model.layers.21.mlp.down_proj',\n",
       " 'model.layers.22.self_attn.q_proj',\n",
       " 'model.layers.22.self_attn.k_proj',\n",
       " 'model.layers.22.self_attn.v_proj',\n",
       " 'model.layers.22.self_attn.o_proj',\n",
       " 'model.layers.22.mlp.gate_proj',\n",
       " 'model.layers.22.mlp.up_proj',\n",
       " 'model.layers.22.mlp.down_proj',\n",
       " 'model.layers.23.self_attn.q_proj',\n",
       " 'model.layers.23.self_attn.k_proj',\n",
       " 'model.layers.23.self_attn.v_proj',\n",
       " 'model.layers.23.self_attn.o_proj',\n",
       " 'model.layers.23.mlp.gate_proj',\n",
       " 'model.layers.23.mlp.up_proj',\n",
       " 'model.layers.23.mlp.down_proj',\n",
       " 'model.layers.24.self_attn.q_proj',\n",
       " 'model.layers.24.self_attn.k_proj',\n",
       " 'model.layers.24.self_attn.v_proj',\n",
       " 'model.layers.24.self_attn.o_proj',\n",
       " 'model.layers.24.mlp.gate_proj',\n",
       " 'model.layers.24.mlp.up_proj',\n",
       " 'model.layers.24.mlp.down_proj',\n",
       " 'model.layers.25.self_attn.q_proj',\n",
       " 'model.layers.25.self_attn.k_proj',\n",
       " 'model.layers.25.self_attn.v_proj',\n",
       " 'model.layers.25.self_attn.o_proj',\n",
       " 'model.layers.25.mlp.gate_proj',\n",
       " 'model.layers.25.mlp.up_proj',\n",
       " 'model.layers.25.mlp.down_proj',\n",
       " 'model.layers.26.self_attn.q_proj',\n",
       " 'model.layers.26.self_attn.k_proj',\n",
       " 'model.layers.26.self_attn.v_proj',\n",
       " 'model.layers.26.self_attn.o_proj',\n",
       " 'model.layers.26.mlp.gate_proj',\n",
       " 'model.layers.26.mlp.up_proj',\n",
       " 'model.layers.26.mlp.down_proj',\n",
       " 'model.layers.27.self_attn.q_proj',\n",
       " 'model.layers.27.self_attn.k_proj',\n",
       " 'model.layers.27.self_attn.v_proj',\n",
       " 'model.layers.27.self_attn.o_proj',\n",
       " 'model.layers.27.mlp.gate_proj',\n",
       " 'model.layers.27.mlp.up_proj',\n",
       " 'model.layers.27.mlp.down_proj',\n",
       " 'model.layers.28.self_attn.q_proj',\n",
       " 'model.layers.28.self_attn.k_proj',\n",
       " 'model.layers.28.self_attn.v_proj',\n",
       " 'model.layers.28.self_attn.o_proj',\n",
       " 'model.layers.28.mlp.gate_proj',\n",
       " 'model.layers.28.mlp.up_proj',\n",
       " 'model.layers.28.mlp.down_proj',\n",
       " 'model.layers.29.self_attn.q_proj',\n",
       " 'model.layers.29.self_attn.k_proj',\n",
       " 'model.layers.29.self_attn.v_proj',\n",
       " 'model.layers.29.self_attn.o_proj',\n",
       " 'model.layers.29.mlp.gate_proj',\n",
       " 'model.layers.29.mlp.up_proj',\n",
       " 'model.layers.29.mlp.down_proj',\n",
       " 'model.layers.30.self_attn.q_proj',\n",
       " 'model.layers.30.self_attn.k_proj',\n",
       " 'model.layers.30.self_attn.v_proj',\n",
       " 'model.layers.30.self_attn.o_proj',\n",
       " 'model.layers.30.mlp.gate_proj',\n",
       " 'model.layers.30.mlp.up_proj',\n",
       " 'model.layers.30.mlp.down_proj',\n",
       " 'model.layers.31.self_attn.q_proj',\n",
       " 'model.layers.31.self_attn.k_proj',\n",
       " 'model.layers.31.self_attn.v_proj',\n",
       " 'model.layers.31.self_attn.o_proj',\n",
       " 'model.layers.31.mlp.gate_proj',\n",
       " 'model.layers.31.mlp.up_proj',\n",
       " 'model.layers.31.mlp.down_proj',\n",
       " 'lm_head']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llmin.utils import get_linear_module_names\n",
    "linear_module_names = get_linear_module_names(model)\n",
    "linear_module_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:23<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "linear_module_names = get_linear_module_names(model)\n",
    "\n",
    "def calculate_similarities(\n",
    "    linear_module_name: str = \"model.layers.{idx}.self_attn.q_proj.weight\",\n",
    "    num_layers = 32\n",
    "):\n",
    "\n",
    "    similarities = []\n",
    "    for i in tqdm(range(0, num_layers)):\n",
    "        for j in range(0, num_layers):\n",
    "            if i != j:\n",
    "                sim = sim_matrix(\n",
    "                    a = model.state_dict()[linear_module_name.format(idx = i)],\n",
    "                    b = model.state_dict()[linear_module_name.format(idx = j)]\n",
    "                ).to(\"cpu\")\n",
    "                idx = (sim==torch.max(sim)).nonzero()[0].to(\"cpu\")\n",
    "                similarities.append({\n",
    "                    \"sim\": sim[idx[0].item(), idx[1].item()],\n",
    "                    \"layer_1\": linear_module_name.format(idx = i),\n",
    "                    \"layer_2\": linear_module_name.format(idx = j)\n",
    "                })\n",
    "    return similarities\n",
    "\n",
    "similarities = calculate_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sim': tensor(0.8633, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.8633, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.8359, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.8359, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.8242, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.8242, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.8164, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.8164, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.8008, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.8008, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.8008, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.8008, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7930, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7930, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7930, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7930, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7891, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7891, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7812, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7812, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7812, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7812, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7578, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7578, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7578, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7578, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7461, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7461, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7344, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7344, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7266, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7266, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7266, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7266, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7266, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7266, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7227, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7227, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7227, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7227, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7109, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7109, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7070, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.7070, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6953, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6953, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6914, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6914, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6914, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6914, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6914, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6914, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6914, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6914, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6875, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6875, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6836, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6836, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6758, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6758, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6719, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6719, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6719, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6719, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6719, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6719, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6719, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6719, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6680, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6680, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6641, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6641, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6641, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6641, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6641, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6641, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6562, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6562, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6523, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6523, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6484, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6484, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6484, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6484, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6406, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6406, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6406, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6406, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6367, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6367, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6289, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6289, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6289, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6289, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6250, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6250, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6250, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6250, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6250, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6250, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6211, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6211, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6133, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6133, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6133, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6133, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6094, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6094, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6094, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6094, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6055, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.6055, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5977, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5977, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5977, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5977, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5977, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5977, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5977, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5977, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5938, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5938, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5898, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5898, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5898, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5898, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5898, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5898, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5859, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5859, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5859, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5859, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5820, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5820, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5781, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5781, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5781, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5781, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5781, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5781, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5781, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5781, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5742, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5742, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5742, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5742, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5664, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5664, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5625, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5625, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5625, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5625, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5586, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5586, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5586, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5586, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5547, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5547, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5547, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5547, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5508, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5508, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5508, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5508, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5469, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5469, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5430, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5430, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5430, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5430, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5430, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5430, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5391, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5391, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5391, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5391, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5352, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5352, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5352, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5352, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5352, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5352, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5312, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5312, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5312, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5312, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5273, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5273, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5273, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5273, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5234, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5234, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5195, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5195, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5156, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5156, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5156, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5156, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5078, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5078, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5078, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5078, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5078, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5078, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5078, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5078, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5039, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5039, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5000, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5000, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5000, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.5000, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4961, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4961, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4961, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4961, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4961, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4961, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4941, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4941, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4941, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4941, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4922, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4922, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4922, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4922, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4922, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4922, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4863, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4863, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4863, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4863, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4844, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4844, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4824, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4824, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4824, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4824, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4785, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4785, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4785, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4785, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4746, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4746, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4648, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4648, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4629, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4629, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4629, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4629, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4609, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4609, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4609, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4609, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4590, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4590, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4590, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4590, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4551, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4551, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4512, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4512, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4512, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4512, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4492, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4492, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4473, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4473, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4453, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4453, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4434, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4434, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4434, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4434, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4414, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4414, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4395, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4395, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4375, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4375, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4355, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4355, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4355, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4355, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4336, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4336, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4336, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4336, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4316, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4316, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4316, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4316, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4297, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4297, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4277, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4277, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4258, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4258, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4258, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4258, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4219, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4219, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4199, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4199, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4199, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4199, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4199, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4199, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4180, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4180, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4180, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4180, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4160, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4160, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4141, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4141, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4121, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4121, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4121, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4121, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4121, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4121, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4102, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4102, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4102, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4102, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4102, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4102, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4102, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4102, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4062, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4062, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4062, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4062, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4043, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4043, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4043, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4043, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4004, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.4004, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3965, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3965, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3965, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3965, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3965, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3965, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3965, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3965, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3945, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3945, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3926, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3926, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3926, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3926, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3906, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3906, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3848, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3848, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3828, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3828, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3789, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3789, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3789, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3789, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3770, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3770, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3770, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3770, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3770, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3770, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3750, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3750, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3711, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3711, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3711, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3711, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3691, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3691, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3672, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3672, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3672, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3672, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3652, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3652, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3652, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3652, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3652, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3652, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3633, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3633, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3633, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3633, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3633, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3633, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3613, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3613, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3613, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3613, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3613, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3613, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3594, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3594, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3594, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3594, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3574, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3574, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3574, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3574, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3555, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3555, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3555, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3555, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3555, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3555, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3555, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3555, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3535, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3535, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3535, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3535, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3535, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3535, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3516, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3516, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3516, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3516, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3516, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3516, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3477, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3477, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3477, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3477, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3477, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3477, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3457, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3457, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3457, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3457, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3438, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3438, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3438, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3438, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3438, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3438, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3418, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3418, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3398, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3398, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3398, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3398, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3398, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3398, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3398, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3398, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3379, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3379, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3379, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3379, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3359, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3359, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3340, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3340, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3320, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3320, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3320, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3320, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3320, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3320, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3301, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3301, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3281, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3281, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3281, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3281, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3242, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3242, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3223, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3223, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3203, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3203, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3184, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3184, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3164, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3164, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3164, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3164, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3164, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3164, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3145, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3145, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3145, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3145, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3125, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3125, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3125, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3125, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3105, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3105, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3105, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3105, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3086, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3086, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3047, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3047, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3027, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3027, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3008, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.3008, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2988, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2988, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2988, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2988, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2969, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2969, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2969, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2969, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2969, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2969, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2969, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2969, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2949, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2949, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2949, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2949, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2949, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2949, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2930, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2930, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2930, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2930, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2930, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2930, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2910, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2910, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2910, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2910, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2910, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2910, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2891, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2891, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2891, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2891, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2852, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2852, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2852, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2852, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2852, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2852, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2832, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2832, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2832, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2832, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2832, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2832, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2812, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2812, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2812, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2812, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2812, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2812, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2793, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2793, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2793, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2793, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2773, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2773, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2773, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2773, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2773, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2773, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2754, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2754, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2754, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2754, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2754, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2754, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2734, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2734, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2734, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2734, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2734, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2734, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2734, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2734, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2715, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2715, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2715, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2715, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2715, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2715, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2715, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2715, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2656, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2656, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2637, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2637, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2637, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2637, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2617, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2617, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2617, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2617, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2578, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2578, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2539, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2539, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2539, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2539, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2520, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2520, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2520, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2520, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2520, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2520, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2520, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2520, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2500, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2500, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2490, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2490, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2490, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2490, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2490, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2490, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2490, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2490, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2480, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2480, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2480, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2480, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2480, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2480, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2471, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2471, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2461, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2461, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2441, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2441, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2432, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2432, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2432, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2432, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2432, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2432, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2412, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2412, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2402, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2402, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2402, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2402, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2402, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2402, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2383, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2383, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2383, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2383, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2383, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2383, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2373, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2373, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2373, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2373, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2373, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2373, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2363, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2363, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2363, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2363, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2363, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2363, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2354, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2354, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2354, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2354, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2344, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2344, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2334, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2334, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2334, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2334, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2334, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2334, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2324, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2324, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2314, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2314, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2305, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2305, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2285, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2285, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2275, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2275, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2266, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2266, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2266, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2266, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2266, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2266, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2246, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2246, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2217, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2217, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2217, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2217, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2207, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2207, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2207, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2207, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2207, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2207, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2178, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2178, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2178, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2178, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2178, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2178, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2168, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2168, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2168, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2168, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2158, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2158, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2158, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2158, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2139, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2139, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2139, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2139, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2129, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2129, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2119, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2119, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2109, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2109, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2100, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2100, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2100, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2100, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2041, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2041, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2021, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2021, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2021, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2021, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2021, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2021, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2012, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2012, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2012, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2012, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2012, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2012, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2002, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.2002, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1992, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1992, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1992, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1992, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1973, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1973, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1963, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1963, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1943, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1943, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1924, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1924, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1914, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1914, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1895, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1895, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1865, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1865, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1816, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1816, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1816, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1816, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1807, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1807, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1797, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1797, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1758, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1758, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1748, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1748, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1738, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1738, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1729, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1729, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1699, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1699, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1670, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1670, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1670, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1670, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1650, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1650, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1650, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1650, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1641, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1641, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1592, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1592, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1562, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1562, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1494, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1494, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1484, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.12.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1484, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.12.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1445, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1445, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1445, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1445, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1426, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1426, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1387, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1387, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1309, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1309, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1309, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1309, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1289, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.3.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1289, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.3.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1270, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1270, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1260, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.4.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1260, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.4.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1230, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1230, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1221, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1221, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1191, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1191, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1167, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.20.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1167, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.20.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1162, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1162, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1157, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1157, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1157, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1157, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1108, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.27.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1108, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.2.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1108, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.27.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1108, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.2.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1084, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.23.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1084, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.26.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1084, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.23.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1084, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.26.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1074, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1074, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1050, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.7.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1050, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.7.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1040, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.5.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1040, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.5.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1030, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.11.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.1030, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.11.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0996, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.6.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0996, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.6.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0991, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.14.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0991, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.14.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0986, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.1.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0986, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.1.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0981, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.24.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0981, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.24.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0967, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.29.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0967, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.29.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0957, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.8.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0957, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.8.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0942, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.30.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0942, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.30.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0933, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.17.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0933, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.31.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0933, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.17.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0933, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.31.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0928, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.25.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0928, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.28.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0928, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.25.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0928, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.28.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0923, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.15.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0923, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.15.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0908, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.10.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0908, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.10.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0903, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.22.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0903, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.22.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0889, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.9.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0889, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.9.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0884, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.21.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0884, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.21.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0869, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.13.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0869, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.13.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0845, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.18.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0845, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.18.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0806, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.16.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0806, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.0.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.19.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0806, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.16.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'},\n",
       " {'sim': tensor(0.0806, dtype=torch.bfloat16),\n",
       "  'layer_1': 'model.layers.19.self_attn.q_proj.weight',\n",
       "  'layer_2': 'model.layers.0.self_attn.q_proj.weight'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(similarities, key = lambda item: item[\"sim\"], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/225 [00:00<00:02, 101.49it/s]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 4194304 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j_module \u001b[38;5;129;01min\u001b[39;00m tqdm(linear_module_names):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i_module \u001b[38;5;241m!=\u001b[39m j_module:\n\u001b[1;32m      7\u001b[0m         sim \u001b[38;5;241m=\u001b[39m \u001b[43msim_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi_module\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mj_module\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m---> 10\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m         idx \u001b[38;5;241m=\u001b[39m (sim\u001b[38;5;241m==\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmax(sim))\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m         similarities\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     13\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msim\u001b[39m\u001b[38;5;124m\"\u001b[39m: sim[idx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem(), idx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()],\n\u001b[1;32m     14\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midx_0\u001b[39m\u001b[38;5;124m\"\u001b[39m: idx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m     15\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midx_1\u001b[39m\u001b[38;5;124m\"\u001b[39m: idx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     16\u001b[0m         })\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 4194304 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sim': tensor(0.3223, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2545),\n",
       "  'idx_1': tensor(2024)},\n",
       " {'sim': tensor(0.1670, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3006),\n",
       "  'idx_1': tensor(1463)},\n",
       " {'sim': tensor(0.1738, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1749),\n",
       "  'idx_1': tensor(2303)},\n",
       " {'sim': tensor(0.1260, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2805),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.1040, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(49),\n",
       "  'idx_1': tensor(1078)},\n",
       " {'sim': tensor(0.0996, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1813),\n",
       "  'idx_1': tensor(3255)},\n",
       " {'sim': tensor(0.1050, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3189),\n",
       "  'idx_1': tensor(122)},\n",
       " {'sim': tensor(0.0957, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1634),\n",
       "  'idx_1': tensor(3275)},\n",
       " {'sim': tensor(0.0889, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1062),\n",
       "  'idx_1': tensor(1270)},\n",
       " {'sim': tensor(0.0908, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3189),\n",
       "  'idx_1': tensor(1787)},\n",
       " {'sim': tensor(0.1030, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3686),\n",
       "  'idx_1': tensor(1404)},\n",
       " {'sim': tensor(0.1484, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(73),\n",
       "  'idx_1': tensor(829)},\n",
       " {'sim': tensor(0.0869, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(424),\n",
       "  'idx_1': tensor(3973)},\n",
       " {'sim': tensor(0.0991, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3875),\n",
       "  'idx_1': tensor(2313)},\n",
       " {'sim': tensor(0.0923, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(138),\n",
       "  'idx_1': tensor(3064)},\n",
       " {'sim': tensor(0.0806, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2715),\n",
       "  'idx_1': tensor(2369)},\n",
       " {'sim': tensor(0.0933, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3836),\n",
       "  'idx_1': tensor(2883)},\n",
       " {'sim': tensor(0.0845, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1847),\n",
       "  'idx_1': tensor(2120)},\n",
       " {'sim': tensor(0.0806, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3205),\n",
       "  'idx_1': tensor(1205)},\n",
       " {'sim': tensor(0.1167, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(134),\n",
       "  'idx_1': tensor(919)},\n",
       " {'sim': tensor(0.0884, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(485),\n",
       "  'idx_1': tensor(4032)},\n",
       " {'sim': tensor(0.0903, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3648),\n",
       "  'idx_1': tensor(371)},\n",
       " {'sim': tensor(0.1084, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3116),\n",
       "  'idx_1': tensor(309)},\n",
       " {'sim': tensor(0.0981, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3718),\n",
       "  'idx_1': tensor(448)},\n",
       " {'sim': tensor(0.0928, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(462),\n",
       "  'idx_1': tensor(2277)},\n",
       " {'sim': tensor(0.1084, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1310),\n",
       "  'idx_1': tensor(1600)},\n",
       " {'sim': tensor(0.1108, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1809),\n",
       "  'idx_1': tensor(256)},\n",
       " {'sim': tensor(0.0928, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3770),\n",
       "  'idx_1': tensor(3840)},\n",
       " {'sim': tensor(0.0967, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(74),\n",
       "  'idx_1': tensor(851)},\n",
       " {'sim': tensor(0.0942, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(412),\n",
       "  'idx_1': tensor(2908)},\n",
       " {'sim': tensor(0.0933, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2617),\n",
       "  'idx_1': tensor(3542)},\n",
       " {'sim': tensor(0.3223, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2024),\n",
       "  'idx_1': tensor(2545)},\n",
       " {'sim': tensor(0.5352, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1082),\n",
       "  'idx_1': tensor(953)},\n",
       " {'sim': tensor(0.3965, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1082),\n",
       "  'idx_1': tensor(2681)},\n",
       " {'sim': tensor(0.3711, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(56),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.2793, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2167),\n",
       "  'idx_1': tensor(3898)},\n",
       " {'sim': tensor(0.2656, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(55),\n",
       "  'idx_1': tensor(3898)},\n",
       " {'sim': tensor(0.2217, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2105),\n",
       "  'idx_1': tensor(3897)},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2),\n",
       "  'idx_1': tensor(3648)},\n",
       " {'sim': tensor(0.1650, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1015),\n",
       "  'idx_1': tensor(3135)},\n",
       " {'sim': tensor(0.1562, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1015),\n",
       "  'idx_1': tensor(1595)},\n",
       " {'sim': tensor(0.1992, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3),\n",
       "  'idx_1': tensor(2241)},\n",
       " {'sim': tensor(0.2021, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1202),\n",
       "  'idx_1': tensor(825)},\n",
       " {'sim': tensor(0.2168, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2),\n",
       "  'idx_1': tensor(4032)},\n",
       " {'sim': tensor(0.1270, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1527),\n",
       "  'idx_1': tensor(572)},\n",
       " {'sim': tensor(0.2207, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3279),\n",
       "  'idx_1': tensor(3064)},\n",
       " {'sim': tensor(0.1191, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1723),\n",
       "  'idx_1': tensor(1598)},\n",
       " {'sim': tensor(0.1650, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2),\n",
       "  'idx_1': tensor(2880)},\n",
       " {'sim': tensor(0.1157, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1527),\n",
       "  'idx_1': tensor(1277)},\n",
       " {'sim': tensor(0.1162, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3910),\n",
       "  'idx_1': tensor(3527)},\n",
       " {'sim': tensor(0.1387, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3245),\n",
       "  'idx_1': tensor(903)},\n",
       " {'sim': tensor(0.1309, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(64),\n",
       "  'idx_1': tensor(4032)},\n",
       " {'sim': tensor(0.1157, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2615),\n",
       "  'idx_1': tensor(1593)},\n",
       " {'sim': tensor(0.1426, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2800),\n",
       "  'idx_1': tensor(3051)},\n",
       " {'sim': tensor(0.1494, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2),\n",
       "  'idx_1': tensor(448)},\n",
       " {'sim': tensor(0.1230, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(69),\n",
       "  'idx_1': tensor(2229)},\n",
       " {'sim': tensor(0.1592, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2909),\n",
       "  'idx_1': tensor(3968)},\n",
       " {'sim': tensor(0.1445, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1200),\n",
       "  'idx_1': tensor(1443)},\n",
       " {'sim': tensor(0.1221, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1027),\n",
       "  'idx_1': tensor(3840)},\n",
       " {'sim': tensor(0.1699, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1446),\n",
       "  'idx_1': tensor(797)},\n",
       " {'sim': tensor(0.1074, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1256),\n",
       "  'idx_1': tensor(4020)},\n",
       " {'sim': tensor(0.0986, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(860),\n",
       "  'idx_1': tensor(661)},\n",
       " {'sim': tensor(0.1670, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1463),\n",
       "  'idx_1': tensor(3006)},\n",
       " {'sim': tensor(0.5352, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(953),\n",
       "  'idx_1': tensor(1082)},\n",
       " {'sim': tensor(0.6953, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3519),\n",
       "  'idx_1': tensor(2681)},\n",
       " {'sim': tensor(0.5586, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(2101)},\n",
       " {'sim': tensor(0.5430, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(117)},\n",
       " {'sim': tensor(0.5195, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1079),\n",
       "  'idx_1': tensor(3898)},\n",
       " {'sim': tensor(0.4316, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(314)},\n",
       " {'sim': tensor(0.4258, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(3830)},\n",
       " {'sim': tensor(0.3613, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(3135)},\n",
       " {'sim': tensor(0.3555, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(1979)},\n",
       " {'sim': tensor(0.3203, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(2239)},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2617),\n",
       "  'idx_1': tensor(892)},\n",
       " {'sim': tensor(0.2520, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1079),\n",
       "  'idx_1': tensor(2487)},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3519),\n",
       "  'idx_1': tensor(1913)},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(696)},\n",
       " {'sim': tensor(0.2930, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(59)},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(3518)},\n",
       " {'sim': tensor(0.2754, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1079),\n",
       "  'idx_1': tensor(1277)},\n",
       " {'sim': tensor(0.2852, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(2807)},\n",
       " {'sim': tensor(0.2520, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(2744)},\n",
       " {'sim': tensor(0.2715, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(3958)},\n",
       " {'sim': tensor(0.2402, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(1913)},\n",
       " {'sim': tensor(0.2617, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(2549)},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(244)},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(2237)},\n",
       " {'sim': tensor(0.2178, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(3385)},\n",
       " {'sim': tensor(0.1963, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(947),\n",
       "  'idx_1': tensor(1401)},\n",
       " {'sim': tensor(0.2002, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1207),\n",
       "  'idx_1': tensor(1662)},\n",
       " {'sim': tensor(0.1914, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3066),\n",
       "  'idx_1': tensor(804)},\n",
       " {'sim': tensor(0.1309, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(953),\n",
       "  'idx_1': tensor(3000)},\n",
       " {'sim': tensor(0.1108, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3463),\n",
       "  'idx_1': tensor(2825)},\n",
       " {'sim': tensor(0.1738, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2303),\n",
       "  'idx_1': tensor(1749)},\n",
       " {'sim': tensor(0.3965, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2681),\n",
       "  'idx_1': tensor(1082)},\n",
       " {'sim': tensor(0.6953, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2681),\n",
       "  'idx_1': tensor(3519)},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2877),\n",
       "  'idx_1': tensor(3965)},\n",
       " {'sim': tensor(0.5781, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2809),\n",
       "  'idx_1': tensor(958)},\n",
       " {'sim': tensor(0.5430, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2681),\n",
       "  'idx_1': tensor(3898)},\n",
       " {'sim': tensor(0.4609, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2681),\n",
       "  'idx_1': tensor(314)},\n",
       " {'sim': tensor(0.4062, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2937),\n",
       "  'idx_1': tensor(3830)},\n",
       " {'sim': tensor(0.3711, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2681),\n",
       "  'idx_1': tensor(3135)},\n",
       " {'sim': tensor(0.3535, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2937),\n",
       "  'idx_1': tensor(1979)},\n",
       " {'sim': tensor(0.3164, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2681),\n",
       "  'idx_1': tensor(2239)},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3382),\n",
       "  'idx_1': tensor(250)},\n",
       " {'sim': tensor(0.2754, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3455),\n",
       "  'idx_1': tensor(4088)},\n",
       " {'sim': tensor(0.2578, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2937),\n",
       "  'idx_1': tensor(1913)},\n",
       " {'sim': tensor(0.2520, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3382),\n",
       "  'idx_1': tensor(1981)},\n",
       " {'sim': tensor(0.2715, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2809),\n",
       "  'idx_1': tensor(59)},\n",
       " {'sim': tensor(0.2471, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1146),\n",
       "  'idx_1': tensor(1531)},\n",
       " {'sim': tensor(0.2490, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2937),\n",
       "  'idx_1': tensor(1277)},\n",
       " {'sim': tensor(0.2715, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2937),\n",
       "  'idx_1': tensor(2807)},\n",
       " {'sim': tensor(0.2334, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2937),\n",
       "  'idx_1': tensor(2872)},\n",
       " {'sim': tensor(0.2432, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2937),\n",
       "  'idx_1': tensor(3958)},\n",
       " {'sim': tensor(0.2354, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2937),\n",
       "  'idx_1': tensor(61)},\n",
       " {'sim': tensor(0.2490, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2681),\n",
       "  'idx_1': tensor(4025)},\n",
       " {'sim': tensor(0.2383, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2877),\n",
       "  'idx_1': tensor(1151)},\n",
       " {'sim': tensor(0.2373, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2937),\n",
       "  'idx_1': tensor(2237)},\n",
       " {'sim': tensor(0.2139, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2877),\n",
       "  'idx_1': tensor(1854)},\n",
       " {'sim': tensor(0.1924, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2877),\n",
       "  'idx_1': tensor(2809)},\n",
       " {'sim': tensor(0.1992, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2937),\n",
       "  'idx_1': tensor(1662)},\n",
       " {'sim': tensor(0.1816, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3429),\n",
       "  'idx_1': tensor(550)},\n",
       " {'sim': tensor(0.1445, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2930),\n",
       "  'idx_1': tensor(3064)},\n",
       " {'sim': tensor(0.1289, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2036),\n",
       "  'idx_1': tensor(3115)},\n",
       " {'sim': tensor(0.1260, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(2805)},\n",
       " {'sim': tensor(0.3711, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(56)},\n",
       " {'sim': tensor(0.5586, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2101),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3965),\n",
       "  'idx_1': tensor(2877)},\n",
       " {'sim': tensor(0.6406, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3965),\n",
       "  'idx_1': tensor(3898)},\n",
       " {'sim': tensor(0.5742, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(248)},\n",
       " {'sim': tensor(0.5000, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(3897)},\n",
       " {'sim': tensor(0.4297, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2101),\n",
       "  'idx_1': tensor(3830)},\n",
       " {'sim': tensor(0.3555, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2101),\n",
       "  'idx_1': tensor(3135)},\n",
       " {'sim': tensor(0.3457, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(570)},\n",
       " {'sim': tensor(0.3516, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(3518)},\n",
       " {'sim': tensor(0.3105, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(122)},\n",
       " {'sim': tensor(0.2891, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(3960)},\n",
       " {'sim': tensor(0.2734, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(3575)},\n",
       " {'sim': tensor(0.2852, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(1981)},\n",
       " {'sim': tensor(0.2773, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(3003)},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(1531)},\n",
       " {'sim': tensor(0.2480, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(3322)},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2603),\n",
       "  'idx_1': tensor(2743)},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(2111)},\n",
       " {'sim': tensor(0.2383, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(947),\n",
       "  'idx_1': tensor(3766)},\n",
       " {'sim': tensor(0.2285, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(3326)},\n",
       " {'sim': tensor(0.2441, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2101),\n",
       "  'idx_1': tensor(373)},\n",
       " {'sim': tensor(0.2490, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(1151)},\n",
       " {'sim': tensor(0.2344, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(1405)},\n",
       " {'sim': tensor(0.2246, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(2805)},\n",
       " {'sim': tensor(0.2119, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(2809)},\n",
       " {'sim': tensor(0.2100, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2678),\n",
       "  'idx_1': tensor(3894)},\n",
       " {'sim': tensor(0.1758, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1572),\n",
       "  'idx_1': tensor(354)},\n",
       " {'sim': tensor(0.1797, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1572),\n",
       "  'idx_1': tensor(417)},\n",
       " {'sim': tensor(0.1748, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1572),\n",
       "  'idx_1': tensor(2465)},\n",
       " {'sim': tensor(0.1040, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1078),\n",
       "  'idx_1': tensor(49)},\n",
       " {'sim': tensor(0.2793, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3898),\n",
       "  'idx_1': tensor(2167)},\n",
       " {'sim': tensor(0.5430, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(117),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.5781, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(958),\n",
       "  'idx_1': tensor(2809)},\n",
       " {'sim': tensor(0.6406, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3898),\n",
       "  'idx_1': tensor(3965)},\n",
       " {'sim': tensor(0.6484, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(574),\n",
       "  'idx_1': tensor(3898)},\n",
       " {'sim': tensor(0.5977, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(574),\n",
       "  'idx_1': tensor(314)},\n",
       " {'sim': tensor(0.4824, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(117),\n",
       "  'idx_1': tensor(3958)},\n",
       " {'sim': tensor(0.4395, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(117),\n",
       "  'idx_1': tensor(3135)},\n",
       " {'sim': tensor(0.3633, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(245),\n",
       "  'idx_1': tensor(1723)},\n",
       " {'sim': tensor(0.3477, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2101),\n",
       "  'idx_1': tensor(3518)},\n",
       " {'sim': tensor(0.3125, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3223),\n",
       "  'idx_1': tensor(789)},\n",
       " {'sim': tensor(0.3613, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2112),\n",
       "  'idx_1': tensor(4032)},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(668),\n",
       "  'idx_1': tensor(2396)},\n",
       " {'sim': tensor(0.2832, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2357),\n",
       "  'idx_1': tensor(1981)},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(117),\n",
       "  'idx_1': tensor(59)},\n",
       " {'sim': tensor(0.2402, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(117),\n",
       "  'idx_1': tensor(3518)},\n",
       " {'sim': tensor(0.2539, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(117),\n",
       "  'idx_1': tensor(1277)},\n",
       " {'sim': tensor(0.2490, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2101),\n",
       "  'idx_1': tensor(3124)},\n",
       " {'sim': tensor(0.2354, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2101),\n",
       "  'idx_1': tensor(2111)},\n",
       " {'sim': tensor(0.2402, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(117),\n",
       "  'idx_1': tensor(1971)},\n",
       " {'sim': tensor(0.2383, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2357),\n",
       "  'idx_1': tensor(1593)},\n",
       " {'sim': tensor(0.2539, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(117),\n",
       "  'idx_1': tensor(373)},\n",
       " {'sim': tensor(0.2520, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(117),\n",
       "  'idx_1': tensor(116)},\n",
       " {'sim': tensor(0.2334, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(117),\n",
       "  'idx_1': tensor(1661)},\n",
       " {'sim': tensor(0.2334, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2101),\n",
       "  'idx_1': tensor(2805)},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2101),\n",
       "  'idx_1': tensor(1401)},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(743),\n",
       "  'idx_1': tensor(4003)},\n",
       " {'sim': tensor(0.2100, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1830),\n",
       "  'idx_1': tensor(2851)},\n",
       " {'sim': tensor(0.1895, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(675),\n",
       "  'idx_1': tensor(3425)},\n",
       " {'sim': tensor(0.2012, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1820),\n",
       "  'idx_1': tensor(2460)},\n",
       " {'sim': tensor(0.0996, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3255),\n",
       "  'idx_1': tensor(1813)},\n",
       " {'sim': tensor(0.2656, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3898),\n",
       "  'idx_1': tensor(55)},\n",
       " {'sim': tensor(0.5195, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3898),\n",
       "  'idx_1': tensor(1079)},\n",
       " {'sim': tensor(0.5430, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3898),\n",
       "  'idx_1': tensor(2681)},\n",
       " {'sim': tensor(0.5742, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(248),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.6484, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3898),\n",
       "  'idx_1': tensor(574)},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3898),\n",
       "  'idx_1': tensor(314)},\n",
       " {'sim': tensor(0.6055, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3898),\n",
       "  'idx_1': tensor(824)},\n",
       " {'sim': tensor(0.4316, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3898),\n",
       "  'idx_1': tensor(3135)},\n",
       " {'sim': tensor(0.4434, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3642),\n",
       "  'idx_1': tensor(1723)},\n",
       " {'sim': tensor(0.3652, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3642),\n",
       "  'idx_1': tensor(2367)},\n",
       " {'sim': tensor(0.4121, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(832),\n",
       "  'idx_1': tensor(0)},\n",
       " {'sim': tensor(0.3633, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3968),\n",
       "  'idx_1': tensor(0)},\n",
       " {'sim': tensor(0.2812, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(409),\n",
       "  'idx_1': tensor(2393)},\n",
       " {'sim': tensor(0.2773, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(314),\n",
       "  'idx_1': tensor(2748)},\n",
       " {'sim': tensor(0.2637, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2493),\n",
       "  'idx_1': tensor(59)},\n",
       " {'sim': tensor(0.2969, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(768),\n",
       "  'idx_1': tensor(832)},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3642),\n",
       "  'idx_1': tensor(1213)},\n",
       " {'sim': tensor(0.2480, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2493),\n",
       "  'idx_1': tensor(2935)},\n",
       " {'sim': tensor(0.2158, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(948),\n",
       "  'idx_1': tensor(1015)},\n",
       " {'sim': tensor(0.2373, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(820),\n",
       "  'idx_1': tensor(3894)},\n",
       " {'sim': tensor(0.2266, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(948),\n",
       "  'idx_1': tensor(1721)},\n",
       " {'sim': tensor(0.2266, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(820),\n",
       "  'idx_1': tensor(3126)},\n",
       " {'sim': tensor(0.2139, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(820),\n",
       "  'idx_1': tensor(52)},\n",
       " {'sim': tensor(0.2109, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3642),\n",
       "  'idx_1': tensor(1661)},\n",
       " {'sim': tensor(0.2363, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3698),\n",
       "  'idx_1': tensor(2741)},\n",
       " {'sim': tensor(0.1943, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(820),\n",
       "  'idx_1': tensor(1401)},\n",
       " {'sim': tensor(0.1807, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(120),\n",
       "  'idx_1': tensor(3894)},\n",
       " {'sim': tensor(0.1670, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(478),\n",
       "  'idx_1': tensor(1824)},\n",
       " {'sim': tensor(0.1641, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(473),\n",
       "  'idx_1': tensor(3414)},\n",
       " {'sim': tensor(0.1729, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3803),\n",
       "  'idx_1': tensor(2460)},\n",
       " {'sim': tensor(0.1050, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(122),\n",
       "  'idx_1': tensor(3189)},\n",
       " {'sim': tensor(0.2217, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3897),\n",
       "  'idx_1': tensor(2105)},\n",
       " {'sim': tensor(0.4316, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(314),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.4609, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(314),\n",
       "  'idx_1': tensor(2681)},\n",
       " {'sim': tensor(0.5000, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3897),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.5977, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(314),\n",
       "  'idx_1': tensor(574)},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(314),\n",
       "  'idx_1': tensor(3898)},\n",
       " {'sim': tensor(0.5820, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(314),\n",
       "  'idx_1': tensor(824)},\n",
       " {'sim': tensor(0.5938, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(58),\n",
       "  'idx_1': tensor(3135)},\n",
       " {'sim': tensor(0.4414, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(314),\n",
       "  'idx_1': tensor(1851)},\n",
       " {'sim': tensor(0.4609, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3897),\n",
       "  'idx_1': tensor(3518)},\n",
       " {'sim': tensor(0.4199, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2518),\n",
       "  'idx_1': tensor(789)},\n",
       " {'sim': tensor(0.3770, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3897),\n",
       "  'idx_1': tensor(4088)},\n",
       " {'sim': tensor(0.3750, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2522),\n",
       "  'idx_1': tensor(2326)},\n",
       " {'sim': tensor(0.3086, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3641),\n",
       "  'idx_1': tensor(1981)},\n",
       " {'sim': tensor(0.2910, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(58),\n",
       "  'idx_1': tensor(59)},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3897),\n",
       "  'idx_1': tensor(1403)},\n",
       " {'sim': tensor(0.2617, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3641),\n",
       "  'idx_1': tensor(3322)},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(314),\n",
       "  'idx_1': tensor(2807)},\n",
       " {'sim': tensor(0.2275, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3897),\n",
       "  'idx_1': tensor(2111)},\n",
       " {'sim': tensor(0.2461, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2613),\n",
       "  'idx_1': tensor(3766)},\n",
       " {'sim': tensor(0.2207, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3897),\n",
       "  'idx_1': tensor(3326)},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2613),\n",
       "  'idx_1': tensor(309)},\n",
       " {'sim': tensor(0.2373, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3897),\n",
       "  'idx_1': tensor(1407)},\n",
       " {'sim': tensor(0.2363, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3897),\n",
       "  'idx_1': tensor(1405)},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3897),\n",
       "  'idx_1': tensor(1854)},\n",
       " {'sim': tensor(0.2021, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3897),\n",
       "  'idx_1': tensor(2809)},\n",
       " {'sim': tensor(0.1973, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2274),\n",
       "  'idx_1': tensor(4003)},\n",
       " {'sim': tensor(0.2012, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2787),\n",
       "  'idx_1': tensor(1824)},\n",
       " {'sim': tensor(0.1816, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3955),\n",
       "  'idx_1': tensor(3637)},\n",
       " {'sim': tensor(0.2158, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2787),\n",
       "  'idx_1': tensor(3809)},\n",
       " {'sim': tensor(0.0957, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3275),\n",
       "  'idx_1': tensor(1634)},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3648),\n",
       "  'idx_1': tensor(2)},\n",
       " {'sim': tensor(0.4258, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3830),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.4062, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3830),\n",
       "  'idx_1': tensor(2937)},\n",
       " {'sim': tensor(0.4297, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3830),\n",
       "  'idx_1': tensor(2101)},\n",
       " {'sim': tensor(0.4824, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3958),\n",
       "  'idx_1': tensor(117)},\n",
       " {'sim': tensor(0.6055, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(824),\n",
       "  'idx_1': tensor(3898)},\n",
       " {'sim': tensor(0.5820, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(824),\n",
       "  'idx_1': tensor(314)},\n",
       " {'sim': tensor(0.5742, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1738),\n",
       "  'idx_1': tensor(3338)},\n",
       " {'sim': tensor(0.6719, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3830),\n",
       "  'idx_1': tensor(1723)},\n",
       " {'sim': tensor(0.4824, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3830),\n",
       "  'idx_1': tensor(2239)},\n",
       " {'sim': tensor(0.4180, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2560),\n",
       "  'idx_1': tensor(320)},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3648),\n",
       "  'idx_1': tensor(4032)},\n",
       " {'sim': tensor(0.3457, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3830),\n",
       "  'idx_1': tensor(572)},\n",
       " {'sim': tensor(0.3027, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3830),\n",
       "  'idx_1': tensor(696)},\n",
       " {'sim': tensor(0.3281, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3830),\n",
       "  'idx_1': tensor(59)},\n",
       " {'sim': tensor(0.3320, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4032),\n",
       "  'idx_1': tensor(3584)},\n",
       " {'sim': tensor(0.2734, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3830),\n",
       "  'idx_1': tensor(1277)},\n",
       " {'sim': tensor(0.2988, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3894),\n",
       "  'idx_1': tensor(3444)},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3766),\n",
       "  'idx_1': tensor(1015)},\n",
       " {'sim': tensor(0.2754, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3766),\n",
       "  'idx_1': tensor(3766)},\n",
       " {'sim': tensor(0.2412, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2787),\n",
       "  'idx_1': tensor(418)},\n",
       " {'sim': tensor(0.2949, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4022),\n",
       "  'idx_1': tensor(309)},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3766),\n",
       "  'idx_1': tensor(436)},\n",
       " {'sim': tensor(0.2314, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3766),\n",
       "  'idx_1': tensor(2743)},\n",
       " {'sim': tensor(0.2178, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2723),\n",
       "  'idx_1': tensor(868)},\n",
       " {'sim': tensor(0.2012, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4022),\n",
       "  'idx_1': tensor(948)},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4032),\n",
       "  'idx_1': tensor(3840)},\n",
       " {'sim': tensor(0.2305, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2787),\n",
       "  'idx_1': tensor(354)},\n",
       " {'sim': tensor(0.2363, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2787),\n",
       "  'idx_1': tensor(3425)},\n",
       " {'sim': tensor(0.2041, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2787),\n",
       "  'idx_1': tensor(2465)},\n",
       " {'sim': tensor(0.0889, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1270),\n",
       "  'idx_1': tensor(1062)},\n",
       " {'sim': tensor(0.1650, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3135),\n",
       "  'idx_1': tensor(1015)},\n",
       " {'sim': tensor(0.3613, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3135),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.3711, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3135),\n",
       "  'idx_1': tensor(2681)},\n",
       " {'sim': tensor(0.3555, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3135),\n",
       "  'idx_1': tensor(2101)},\n",
       " {'sim': tensor(0.4395, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3135),\n",
       "  'idx_1': tensor(117)},\n",
       " {'sim': tensor(0.4316, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3135),\n",
       "  'idx_1': tensor(3898)},\n",
       " {'sim': tensor(0.5938, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3135),\n",
       "  'idx_1': tensor(58)},\n",
       " {'sim': tensor(0.5742, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3338),\n",
       "  'idx_1': tensor(1738)},\n",
       " {'sim': tensor(0.5977, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3135),\n",
       "  'idx_1': tensor(1851)},\n",
       " {'sim': tensor(0.6250, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3135),\n",
       "  'idx_1': tensor(2239)},\n",
       " {'sim': tensor(0.4785, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3436),\n",
       "  'idx_1': tensor(1003)},\n",
       " {'sim': tensor(0.4102, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3135),\n",
       "  'idx_1': tensor(3896)},\n",
       " {'sim': tensor(0.4258, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3295),\n",
       "  'idx_1': tensor(2336)},\n",
       " {'sim': tensor(0.3535, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(53),\n",
       "  'idx_1': tensor(1981)},\n",
       " {'sim': tensor(0.3477, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3436),\n",
       "  'idx_1': tensor(1003)},\n",
       " {'sim': tensor(0.3848, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(292),\n",
       "  'idx_1': tensor(3171)},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3295),\n",
       "  'idx_1': tensor(28)},\n",
       " {'sim': tensor(0.3555, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(301),\n",
       "  'idx_1': tensor(1194)},\n",
       " {'sim': tensor(0.3281, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(292),\n",
       "  'idx_1': tensor(1699)},\n",
       " {'sim': tensor(0.3164, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(292),\n",
       "  'idx_1': tensor(36)},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(365),\n",
       "  'idx_1': tensor(42)},\n",
       " {'sim': tensor(0.3398, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3436),\n",
       "  'idx_1': tensor(1642)},\n",
       " {'sim': tensor(0.3613, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3436),\n",
       "  'idx_1': tensor(1515)},\n",
       " {'sim': tensor(0.2969, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(365),\n",
       "  'idx_1': tensor(2154)},\n",
       " {'sim': tensor(0.2949, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(365),\n",
       "  'idx_1': tensor(1898)},\n",
       " {'sim': tensor(0.3398, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3436),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.2734, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(301),\n",
       "  'idx_1': tensor(3308)},\n",
       " {'sim': tensor(0.3047, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3436),\n",
       "  'idx_1': tensor(1387)},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3692),\n",
       "  'idx_1': tensor(363)},\n",
       " {'sim': tensor(0.3164, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3308),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.0908, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1787),\n",
       "  'idx_1': tensor(3189)},\n",
       " {'sim': tensor(0.1562, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1595),\n",
       "  'idx_1': tensor(1015)},\n",
       " {'sim': tensor(0.3555, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1979),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.3535, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1979),\n",
       "  'idx_1': tensor(2937)},\n",
       " {'sim': tensor(0.3457, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(570),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.3633, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1723),\n",
       "  'idx_1': tensor(245)},\n",
       " {'sim': tensor(0.4434, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1723),\n",
       "  'idx_1': tensor(3642)},\n",
       " {'sim': tensor(0.4414, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1851),\n",
       "  'idx_1': tensor(314)},\n",
       " {'sim': tensor(0.6719, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1723),\n",
       "  'idx_1': tensor(3830)},\n",
       " {'sim': tensor(0.5977, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1851),\n",
       "  'idx_1': tensor(3135)},\n",
       " {'sim': tensor(0.6523, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1723),\n",
       "  'idx_1': tensor(1983)},\n",
       " {'sim': tensor(0.5977, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(570),\n",
       "  'idx_1': tensor(122)},\n",
       " {'sim': tensor(0.5234, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(570),\n",
       "  'idx_1': tensor(3960)},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1723),\n",
       "  'idx_1': tensor(572)},\n",
       " {'sim': tensor(0.3965, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1723),\n",
       "  'idx_1': tensor(696)},\n",
       " {'sim': tensor(0.3926, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1723),\n",
       "  'idx_1': tensor(59)},\n",
       " {'sim': tensor(0.3574, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(292),\n",
       "  'idx_1': tensor(3363)},\n",
       " {'sim': tensor(0.2969, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1723),\n",
       "  'idx_1': tensor(1213)},\n",
       " {'sim': tensor(0.2910, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1723),\n",
       "  'idx_1': tensor(2807)},\n",
       " {'sim': tensor(0.2715, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(356),\n",
       "  'idx_1': tensor(1699)},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(292),\n",
       "  'idx_1': tensor(612)},\n",
       " {'sim': tensor(0.2207, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(755),\n",
       "  'idx_1': tensor(2941)},\n",
       " {'sim': tensor(0.2324, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(292),\n",
       "  'idx_1': tensor(1699)},\n",
       " {'sim': tensor(0.2178, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(755),\n",
       "  'idx_1': tensor(244)},\n",
       " {'sim': tensor(0.2432, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(292),\n",
       "  'idx_1': tensor(1380)},\n",
       " {'sim': tensor(0.2217, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(292),\n",
       "  'idx_1': tensor(802)},\n",
       " {'sim': tensor(0.2021, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(356),\n",
       "  'idx_1': tensor(3491)},\n",
       " {'sim': tensor(0.2432, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(292),\n",
       "  'idx_1': tensor(2020)},\n",
       " {'sim': tensor(0.2773, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(356),\n",
       "  'idx_1': tensor(2851)},\n",
       " {'sim': tensor(0.2129, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(292),\n",
       "  'idx_1': tensor(3425)},\n",
       " {'sim': tensor(0.1865, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2363),\n",
       "  'idx_1': tensor(2743)},\n",
       " {'sim': tensor(0.1030, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1343),\n",
       "  'idx_1': tensor(3875)},\n",
       " {'sim': tensor(0.1992, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2241),\n",
       "  'idx_1': tensor(3)},\n",
       " {'sim': tensor(0.3203, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2239),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.3164, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2239),\n",
       "  'idx_1': tensor(2681)},\n",
       " {'sim': tensor(0.3516, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3518),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.3477, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3518),\n",
       "  'idx_1': tensor(2101)},\n",
       " {'sim': tensor(0.3652, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2367),\n",
       "  'idx_1': tensor(3642)},\n",
       " {'sim': tensor(0.4609, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3518),\n",
       "  'idx_1': tensor(3897)},\n",
       " {'sim': tensor(0.4824, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2239),\n",
       "  'idx_1': tensor(3830)},\n",
       " {'sim': tensor(0.6250, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2239),\n",
       "  'idx_1': tensor(3135)},\n",
       " {'sim': tensor(0.6523, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1983),\n",
       "  'idx_1': tensor(1723)},\n",
       " {'sim': tensor(0.6758, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3518),\n",
       "  'idx_1': tensor(122)},\n",
       " {'sim': tensor(0.6680, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3518),\n",
       "  'idx_1': tensor(3960)},\n",
       " {'sim': tensor(0.5430, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1828),\n",
       "  'idx_1': tensor(2404)},\n",
       " {'sim': tensor(0.5859, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3134),\n",
       "  'idx_1': tensor(1981)},\n",
       " {'sim': tensor(0.4922, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3710),\n",
       "  'idx_1': tensor(3003)},\n",
       " {'sim': tensor(0.4375, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3518),\n",
       "  'idx_1': tensor(1531)},\n",
       " {'sim': tensor(0.3691, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1883),\n",
       "  'idx_1': tensor(283)},\n",
       " {'sim': tensor(0.3398, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2367),\n",
       "  'idx_1': tensor(2807)},\n",
       " {'sim': tensor(0.3672, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1898),\n",
       "  'idx_1': tensor(4073)},\n",
       " {'sim': tensor(0.3652, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1828),\n",
       "  'idx_1': tensor(228)},\n",
       " {'sim': tensor(0.2988, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1834),\n",
       "  'idx_1': tensor(874)},\n",
       " {'sim': tensor(0.3184, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1892),\n",
       "  'idx_1': tensor(1699)},\n",
       " {'sim': tensor(0.2812, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3755),\n",
       "  'idx_1': tensor(810)},\n",
       " {'sim': tensor(0.2637, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1636),\n",
       "  'idx_1': tensor(1380)},\n",
       " {'sim': tensor(0.2500, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3755),\n",
       "  'idx_1': tensor(1834)},\n",
       " {'sim': tensor(0.2266, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1572),\n",
       "  'idx_1': tensor(3813)},\n",
       " {'sim': tensor(0.2910, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1572),\n",
       "  'idx_1': tensor(1956)},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1572),\n",
       "  'idx_1': tensor(1828)},\n",
       " {'sim': tensor(0.2734, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1636),\n",
       "  'idx_1': tensor(3425)},\n",
       " {'sim': tensor(0.2168, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2656),\n",
       "  'idx_1': tensor(2465)},\n",
       " {'sim': tensor(0.1484, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(829),\n",
       "  'idx_1': tensor(73)},\n",
       " {'sim': tensor(0.2021, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(825),\n",
       "  'idx_1': tensor(1202)},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(892),\n",
       "  'idx_1': tensor(2617)},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(250),\n",
       "  'idx_1': tensor(3382)},\n",
       " {'sim': tensor(0.3105, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(122),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.3125, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(789),\n",
       "  'idx_1': tensor(3223)},\n",
       " {'sim': tensor(0.4121, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(0),\n",
       "  'idx_1': tensor(832)},\n",
       " {'sim': tensor(0.4199, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(789),\n",
       "  'idx_1': tensor(2518)},\n",
       " {'sim': tensor(0.4180, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(320),\n",
       "  'idx_1': tensor(2560)},\n",
       " {'sim': tensor(0.4785, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1003),\n",
       "  'idx_1': tensor(3436)},\n",
       " {'sim': tensor(0.5977, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(122),\n",
       "  'idx_1': tensor(570)},\n",
       " {'sim': tensor(0.6758, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(122),\n",
       "  'idx_1': tensor(3518)},\n",
       " {'sim': tensor(0.6914, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(122),\n",
       "  'idx_1': tensor(3960)},\n",
       " {'sim': tensor(0.5781, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(122),\n",
       "  'idx_1': tensor(3575)},\n",
       " {'sim': tensor(0.5508, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(122),\n",
       "  'idx_1': tensor(1981)},\n",
       " {'sim': tensor(0.4863, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(122),\n",
       "  'idx_1': tensor(3003)},\n",
       " {'sim': tensor(0.5156, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(0),\n",
       "  'idx_1': tensor(1472)},\n",
       " {'sim': tensor(0.3633, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4085),\n",
       "  'idx_1': tensor(3322)},\n",
       " {'sim': tensor(0.3965, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3684),\n",
       "  'idx_1': tensor(1188)},\n",
       " {'sim': tensor(0.3574, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3684),\n",
       "  'idx_1': tensor(4068)},\n",
       " {'sim': tensor(0.3301, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3684),\n",
       "  'idx_1': tensor(2148)},\n",
       " {'sim': tensor(0.3145, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(865),\n",
       "  'idx_1': tensor(418)},\n",
       " {'sim': tensor(0.3320, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3684),\n",
       "  'idx_1': tensor(1572)},\n",
       " {'sim': tensor(0.3125, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3626),\n",
       "  'idx_1': tensor(874)},\n",
       " {'sim': tensor(0.2969, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3626),\n",
       "  'idx_1': tensor(2154)},\n",
       " {'sim': tensor(0.2930, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3626),\n",
       "  'idx_1': tensor(1898)},\n",
       " {'sim': tensor(0.2812, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1003),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(865),\n",
       "  'idx_1': tensor(4003)},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1003),\n",
       "  'idx_1': tensor(1387)},\n",
       " {'sim': tensor(0.2832, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3680),\n",
       "  'idx_1': tensor(3425)},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1003),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.0869, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3907),\n",
       "  'idx_1': tensor(1562)},\n",
       " {'sim': tensor(0.2168, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4032),\n",
       "  'idx_1': tensor(2)},\n",
       " {'sim': tensor(0.2520, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2487),\n",
       "  'idx_1': tensor(1079)},\n",
       " {'sim': tensor(0.2754, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4088),\n",
       "  'idx_1': tensor(3455)},\n",
       " {'sim': tensor(0.2891, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3960),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.3613, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4032),\n",
       "  'idx_1': tensor(2112)},\n",
       " {'sim': tensor(0.3633, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(0),\n",
       "  'idx_1': tensor(3968)},\n",
       " {'sim': tensor(0.3770, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4088),\n",
       "  'idx_1': tensor(3897)},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4032),\n",
       "  'idx_1': tensor(3648)},\n",
       " {'sim': tensor(0.4102, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3896),\n",
       "  'idx_1': tensor(3135)},\n",
       " {'sim': tensor(0.5234, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3960),\n",
       "  'idx_1': tensor(570)},\n",
       " {'sim': tensor(0.6680, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3960),\n",
       "  'idx_1': tensor(3518)},\n",
       " {'sim': tensor(0.6914, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3960),\n",
       "  'idx_1': tensor(122)},\n",
       " {'sim': tensor(0.6133, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3960),\n",
       "  'idx_1': tensor(3575)},\n",
       " {'sim': tensor(0.5898, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3960),\n",
       "  'idx_1': tensor(1981)},\n",
       " {'sim': tensor(0.5352, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3062),\n",
       "  'idx_1': tensor(3003)},\n",
       " {'sim': tensor(0.5078, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3960),\n",
       "  'idx_1': tensor(1531)},\n",
       " {'sim': tensor(0.4102, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3896),\n",
       "  'idx_1': tensor(1277)},\n",
       " {'sim': tensor(0.3652, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4019),\n",
       "  'idx_1': tensor(181)},\n",
       " {'sim': tensor(0.3320, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3960),\n",
       "  'idx_1': tensor(951)},\n",
       " {'sim': tensor(0.3398, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(683),\n",
       "  'idx_1': tensor(1387)},\n",
       " {'sim': tensor(0.3477, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(683),\n",
       "  'idx_1': tensor(426)},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(747),\n",
       "  'idx_1': tensor(1962)},\n",
       " {'sim': tensor(0.3535, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(683),\n",
       "  'idx_1': tensor(874)},\n",
       " {'sim': tensor(0.3008, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(683),\n",
       "  'idx_1': tensor(2154)},\n",
       " {'sim': tensor(0.3242, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(683),\n",
       "  'idx_1': tensor(1898)},\n",
       " {'sim': tensor(0.2891, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(747),\n",
       "  'idx_1': tensor(3755)},\n",
       " {'sim': tensor(0.2793, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(683),\n",
       "  'idx_1': tensor(2027)},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(747),\n",
       "  'idx_1': tensor(1195)},\n",
       " {'sim': tensor(0.3145, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(683),\n",
       "  'idx_1': tensor(363)},\n",
       " {'sim': tensor(0.2480, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1003),\n",
       "  'idx_1': tensor(3755)},\n",
       " {'sim': tensor(0.0991, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2313),\n",
       "  'idx_1': tensor(3875)},\n",
       " {'sim': tensor(0.1270, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(572),\n",
       "  'idx_1': tensor(1527)},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1913),\n",
       "  'idx_1': tensor(3519)},\n",
       " {'sim': tensor(0.2578, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1913),\n",
       "  'idx_1': tensor(2937)},\n",
       " {'sim': tensor(0.2734, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3575),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2396),\n",
       "  'idx_1': tensor(668)},\n",
       " {'sim': tensor(0.2812, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2393),\n",
       "  'idx_1': tensor(409)},\n",
       " {'sim': tensor(0.3750, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2326),\n",
       "  'idx_1': tensor(2522)},\n",
       " {'sim': tensor(0.3457, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(572),\n",
       "  'idx_1': tensor(3830)},\n",
       " {'sim': tensor(0.4258, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2336),\n",
       "  'idx_1': tensor(3295)},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(572),\n",
       "  'idx_1': tensor(1723)},\n",
       " {'sim': tensor(0.5430, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2404),\n",
       "  'idx_1': tensor(1828)},\n",
       " {'sim': tensor(0.5781, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3575),\n",
       "  'idx_1': tensor(122)},\n",
       " {'sim': tensor(0.6133, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3575),\n",
       "  'idx_1': tensor(3960)},\n",
       " {'sim': tensor(0.6133, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2174),\n",
       "  'idx_1': tensor(1981)},\n",
       " {'sim': tensor(0.5977, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3575),\n",
       "  'idx_1': tensor(3003)},\n",
       " {'sim': tensor(0.5273, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3575),\n",
       "  'idx_1': tensor(1403)},\n",
       " {'sim': tensor(0.4863, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2404),\n",
       "  'idx_1': tensor(100)},\n",
       " {'sim': tensor(0.4844, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2340),\n",
       "  'idx_1': tensor(1252)},\n",
       " {'sim': tensor(0.4102, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3113),\n",
       "  'idx_1': tensor(4073)},\n",
       " {'sim': tensor(0.4453, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2404),\n",
       "  'idx_1': tensor(228)},\n",
       " {'sim': tensor(0.4141, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2410),\n",
       "  'idx_1': tensor(170)},\n",
       " {'sim': tensor(0.4102, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2793),\n",
       "  'idx_1': tensor(1898)},\n",
       " {'sim': tensor(0.4121, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2410),\n",
       "  'idx_1': tensor(874)},\n",
       " {'sim': tensor(0.3516, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2410),\n",
       "  'idx_1': tensor(2154)},\n",
       " {'sim': tensor(0.3379, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(427),\n",
       "  'idx_1': tensor(1898)},\n",
       " {'sim': tensor(0.3906, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(491),\n",
       "  'idx_1': tensor(3755)},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(427),\n",
       "  'idx_1': tensor(2027)},\n",
       " {'sim': tensor(0.3438, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(491),\n",
       "  'idx_1': tensor(1195)},\n",
       " {'sim': tensor(0.3418, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(427),\n",
       "  'idx_1': tensor(363)},\n",
       " {'sim': tensor(0.3438, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(491),\n",
       "  'idx_1': tensor(3755)},\n",
       " {'sim': tensor(0.0923, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3064),\n",
       "  'idx_1': tensor(138)},\n",
       " {'sim': tensor(0.2207, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3064),\n",
       "  'idx_1': tensor(3279)},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(696),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.2520, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1981),\n",
       "  'idx_1': tensor(3382)},\n",
       " {'sim': tensor(0.2852, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1981),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.2832, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1981),\n",
       "  'idx_1': tensor(2357)},\n",
       " {'sim': tensor(0.2773, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2748),\n",
       "  'idx_1': tensor(314)},\n",
       " {'sim': tensor(0.3086, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1981),\n",
       "  'idx_1': tensor(3641)},\n",
       " {'sim': tensor(0.3027, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(696),\n",
       "  'idx_1': tensor(3830)},\n",
       " {'sim': tensor(0.3535, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1981),\n",
       "  'idx_1': tensor(53)},\n",
       " {'sim': tensor(0.3965, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(696),\n",
       "  'idx_1': tensor(1723)},\n",
       " {'sim': tensor(0.5859, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1981),\n",
       "  'idx_1': tensor(3134)},\n",
       " {'sim': tensor(0.5508, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1981),\n",
       "  'idx_1': tensor(122)},\n",
       " {'sim': tensor(0.5898, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1981),\n",
       "  'idx_1': tensor(3960)},\n",
       " {'sim': tensor(0.6133, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1981),\n",
       "  'idx_1': tensor(2174)},\n",
       " {'sim': tensor(0.6875, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1981),\n",
       "  'idx_1': tensor(3003)},\n",
       " {'sim': tensor(0.6562, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1853),\n",
       "  'idx_1': tensor(1403)},\n",
       " {'sim': tensor(0.5781, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1981),\n",
       "  'idx_1': tensor(3322)},\n",
       " {'sim': tensor(0.5312, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1981),\n",
       "  'idx_1': tensor(181)},\n",
       " {'sim': tensor(0.4512, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1981),\n",
       "  'idx_1': tensor(2111)},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(938),\n",
       "  'idx_1': tensor(170)},\n",
       " {'sim': tensor(0.4492, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(938),\n",
       "  'idx_1': tensor(810)},\n",
       " {'sim': tensor(0.4629, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(938),\n",
       "  'idx_1': tensor(1578)},\n",
       " {'sim': tensor(0.3770, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2154),\n",
       "  'idx_1': tensor(810)},\n",
       " {'sim': tensor(0.3340, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(235),\n",
       "  'idx_1': tensor(1323)},\n",
       " {'sim': tensor(0.3379, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2154),\n",
       "  'idx_1': tensor(1834)},\n",
       " {'sim': tensor(0.3105, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2218),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1002),\n",
       "  'idx_1': tensor(2346)},\n",
       " {'sim': tensor(0.2949, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2218),\n",
       "  'idx_1': tensor(1259)},\n",
       " {'sim': tensor(0.2832, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(235),\n",
       "  'idx_1': tensor(299)},\n",
       " {'sim': tensor(0.2852, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(171),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.0806, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2369),\n",
       "  'idx_1': tensor(2715)},\n",
       " {'sim': tensor(0.1191, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1598),\n",
       "  'idx_1': tensor(1723)},\n",
       " {'sim': tensor(0.2930, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(59),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.2715, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(59),\n",
       "  'idx_1': tensor(2809)},\n",
       " {'sim': tensor(0.2773, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3003),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(59),\n",
       "  'idx_1': tensor(117)},\n",
       " {'sim': tensor(0.2637, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(59),\n",
       "  'idx_1': tensor(2493)},\n",
       " {'sim': tensor(0.2910, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(59),\n",
       "  'idx_1': tensor(58)},\n",
       " {'sim': tensor(0.3281, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(59),\n",
       "  'idx_1': tensor(3830)},\n",
       " {'sim': tensor(0.3477, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1003),\n",
       "  'idx_1': tensor(3436)},\n",
       " {'sim': tensor(0.3926, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(59),\n",
       "  'idx_1': tensor(1723)},\n",
       " {'sim': tensor(0.4922, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3003),\n",
       "  'idx_1': tensor(3710)},\n",
       " {'sim': tensor(0.4863, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3003),\n",
       "  'idx_1': tensor(122)},\n",
       " {'sim': tensor(0.5352, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3003),\n",
       "  'idx_1': tensor(3062)},\n",
       " {'sim': tensor(0.5977, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3003),\n",
       "  'idx_1': tensor(3575)},\n",
       " {'sim': tensor(0.6875, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3003),\n",
       "  'idx_1': tensor(1981)},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1854),\n",
       "  'idx_1': tensor(3262)},\n",
       " {'sim': tensor(0.6484, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(315),\n",
       "  'idx_1': tensor(1277)},\n",
       " {'sim': tensor(0.6094, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(59),\n",
       "  'idx_1': tensor(2807)},\n",
       " {'sim': tensor(0.5156, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(59),\n",
       "  'idx_1': tensor(2744)},\n",
       " {'sim': tensor(0.5078, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2922),\n",
       "  'idx_1': tensor(106)},\n",
       " {'sim': tensor(0.4961, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2858),\n",
       "  'idx_1': tensor(810)},\n",
       " {'sim': tensor(0.4922, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2858),\n",
       "  'idx_1': tensor(1834)},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1003),\n",
       "  'idx_1': tensor(1515)},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(59),\n",
       "  'idx_1': tensor(2237)},\n",
       " {'sim': tensor(0.3359, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1700),\n",
       "  'idx_1': tensor(1828)},\n",
       " {'sim': tensor(0.3945, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1003),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.3594, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2922),\n",
       "  'idx_1': tensor(2346)},\n",
       " {'sim': tensor(0.3555, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1003),\n",
       "  'idx_1': tensor(1259)},\n",
       " {'sim': tensor(0.2930, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2922),\n",
       "  'idx_1': tensor(1066)},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1003),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.0933, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2883),\n",
       "  'idx_1': tensor(3836)},\n",
       " {'sim': tensor(0.1650, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2880),\n",
       "  'idx_1': tensor(2)},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3518),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.2471, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1531),\n",
       "  'idx_1': tensor(1146)},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1531),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.2402, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1531),\n",
       "  'idx_1': tensor(2357)},\n",
       " {'sim': tensor(0.2969, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(832),\n",
       "  'idx_1': tensor(768)},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1403),\n",
       "  'idx_1': tensor(3897)},\n",
       " {'sim': tensor(0.3320, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3584),\n",
       "  'idx_1': tensor(4032)},\n",
       " {'sim': tensor(0.3848, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3171),\n",
       "  'idx_1': tensor(292)},\n",
       " {'sim': tensor(0.3574, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3363),\n",
       "  'idx_1': tensor(292)},\n",
       " {'sim': tensor(0.4375, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1531),\n",
       "  'idx_1': tensor(3518)},\n",
       " {'sim': tensor(0.5156, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1472),\n",
       "  'idx_1': tensor(0)},\n",
       " {'sim': tensor(0.5078, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1531),\n",
       "  'idx_1': tensor(3960)},\n",
       " {'sim': tensor(0.5273, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1403),\n",
       "  'idx_1': tensor(3575)},\n",
       " {'sim': tensor(0.6562, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1403),\n",
       "  'idx_1': tensor(1853)},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3262),\n",
       "  'idx_1': tensor(1854)},\n",
       " {'sim': tensor(0.7266, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1403),\n",
       "  'idx_1': tensor(3322)},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1403),\n",
       "  'idx_1': tensor(53)},\n",
       " {'sim': tensor(0.6406, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1403),\n",
       "  'idx_1': tensor(951)},\n",
       " {'sim': tensor(0.5273, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3370),\n",
       "  'idx_1': tensor(106)},\n",
       " {'sim': tensor(0.5469, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3370),\n",
       "  'idx_1': tensor(874)},\n",
       " {'sim': tensor(0.5547, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3370),\n",
       "  'idx_1': tensor(1770)},\n",
       " {'sim': tensor(0.4785, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3434),\n",
       "  'idx_1': tensor(810)},\n",
       " {'sim': tensor(0.4199, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3434),\n",
       "  'idx_1': tensor(2090)},\n",
       " {'sim': tensor(0.4551, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3434),\n",
       "  'idx_1': tensor(1834)},\n",
       " {'sim': tensor(0.3926, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3370),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.4746, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3370),\n",
       "  'idx_1': tensor(2346)},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3171),\n",
       "  'idx_1': tensor(2851)},\n",
       " {'sim': tensor(0.3770, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3434),\n",
       "  'idx_1': tensor(299)},\n",
       " {'sim': tensor(0.4043, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3370),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.0845, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2120),\n",
       "  'idx_1': tensor(1847)},\n",
       " {'sim': tensor(0.1157, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1277),\n",
       "  'idx_1': tensor(1527)},\n",
       " {'sim': tensor(0.2754, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1277),\n",
       "  'idx_1': tensor(1079)},\n",
       " {'sim': tensor(0.2490, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1277),\n",
       "  'idx_1': tensor(2937)},\n",
       " {'sim': tensor(0.2480, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3322),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.2539, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1277),\n",
       "  'idx_1': tensor(117)},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1213),\n",
       "  'idx_1': tensor(3642)},\n",
       " {'sim': tensor(0.2617, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3322),\n",
       "  'idx_1': tensor(3641)},\n",
       " {'sim': tensor(0.2734, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1277),\n",
       "  'idx_1': tensor(3830)},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(28),\n",
       "  'idx_1': tensor(3295)},\n",
       " {'sim': tensor(0.2969, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1213),\n",
       "  'idx_1': tensor(1723)},\n",
       " {'sim': tensor(0.3691, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(283),\n",
       "  'idx_1': tensor(1883)},\n",
       " {'sim': tensor(0.3633, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3322),\n",
       "  'idx_1': tensor(4085)},\n",
       " {'sim': tensor(0.4102, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1277),\n",
       "  'idx_1': tensor(3896)},\n",
       " {'sim': tensor(0.4863, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(100),\n",
       "  'idx_1': tensor(2404)},\n",
       " {'sim': tensor(0.5781, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3322),\n",
       "  'idx_1': tensor(1981)},\n",
       " {'sim': tensor(0.6484, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1277),\n",
       "  'idx_1': tensor(315)},\n",
       " {'sim': tensor(0.7266, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3322),\n",
       "  'idx_1': tensor(1403)},\n",
       " {'sim': tensor(0.7109, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1213),\n",
       "  'idx_1': tensor(2807)},\n",
       " {'sim': tensor(0.6641, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3322),\n",
       "  'idx_1': tensor(951)},\n",
       " {'sim': tensor(0.5625, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1213),\n",
       "  'idx_1': tensor(4086)},\n",
       " {'sim': tensor(0.5312, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2858),\n",
       "  'idx_1': tensor(874)},\n",
       " {'sim': tensor(0.5000, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2858),\n",
       "  'idx_1': tensor(1770)},\n",
       " {'sim': tensor(0.4941, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1515),\n",
       "  'idx_1': tensor(1515)},\n",
       " {'sim': tensor(0.4590, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1277),\n",
       "  'idx_1': tensor(2237)},\n",
       " {'sim': tensor(0.4180, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2922),\n",
       "  'idx_1': tensor(1834)},\n",
       " {'sim': tensor(0.4434, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1451),\n",
       "  'idx_1': tensor(3755)},\n",
       " {'sim': tensor(0.4043, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1835),\n",
       "  'idx_1': tensor(1963)},\n",
       " {'sim': tensor(0.4336, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1515),\n",
       "  'idx_1': tensor(1259)},\n",
       " {'sim': tensor(0.3965, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1835),\n",
       "  'idx_1': tensor(427)},\n",
       " {'sim': tensor(0.4473, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1515),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.0806, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1205),\n",
       "  'idx_1': tensor(3205)},\n",
       " {'sim': tensor(0.1162, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3527),\n",
       "  'idx_1': tensor(3910)},\n",
       " {'sim': tensor(0.2852, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2807),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.2715, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2807),\n",
       "  'idx_1': tensor(2937)},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2743),\n",
       "  'idx_1': tensor(2603)},\n",
       " {'sim': tensor(0.2490, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3124),\n",
       "  'idx_1': tensor(2101)},\n",
       " {'sim': tensor(0.2480, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2935),\n",
       "  'idx_1': tensor(2493)},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2807),\n",
       "  'idx_1': tensor(314)},\n",
       " {'sim': tensor(0.2988, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3444),\n",
       "  'idx_1': tensor(3894)},\n",
       " {'sim': tensor(0.3555, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1194),\n",
       "  'idx_1': tensor(301)},\n",
       " {'sim': tensor(0.2910, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2807),\n",
       "  'idx_1': tensor(1723)},\n",
       " {'sim': tensor(0.3398, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2807),\n",
       "  'idx_1': tensor(2367)},\n",
       " {'sim': tensor(0.3965, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1188),\n",
       "  'idx_1': tensor(3684)},\n",
       " {'sim': tensor(0.3652, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(181),\n",
       "  'idx_1': tensor(4019)},\n",
       " {'sim': tensor(0.4844, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1252),\n",
       "  'idx_1': tensor(2340)},\n",
       " {'sim': tensor(0.5312, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(181),\n",
       "  'idx_1': tensor(1981)},\n",
       " {'sim': tensor(0.6094, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2807),\n",
       "  'idx_1': tensor(59)},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(53),\n",
       "  'idx_1': tensor(1403)},\n",
       " {'sim': tensor(0.7109, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2807),\n",
       "  'idx_1': tensor(1213)},\n",
       " {'sim': tensor(0.7578, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2807),\n",
       "  'idx_1': tensor(2744)},\n",
       " {'sim': tensor(0.7266, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2807),\n",
       "  'idx_1': tensor(3702)},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2807),\n",
       "  'idx_1': tensor(1913)},\n",
       " {'sim': tensor(0.6250, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2935),\n",
       "  'idx_1': tensor(568)},\n",
       " {'sim': tensor(0.5391, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1258),\n",
       "  'idx_1': tensor(874)},\n",
       " {'sim': tensor(0.5078, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2935),\n",
       "  'idx_1': tensor(2807)},\n",
       " {'sim': tensor(0.4355, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1258),\n",
       "  'idx_1': tensor(1898)},\n",
       " {'sim': tensor(0.3828, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(53),\n",
       "  'idx_1': tensor(3065)},\n",
       " {'sim': tensor(0.4199, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2427),\n",
       "  'idx_1': tensor(1599)},\n",
       " {'sim': tensor(0.3672, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2212),\n",
       "  'idx_1': tensor(2851)},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1107),\n",
       "  'idx_1': tensor(3414)},\n",
       " {'sim': tensor(0.3516, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2233),\n",
       "  'idx_1': tensor(2550)},\n",
       " {'sim': tensor(0.1167, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(919),\n",
       "  'idx_1': tensor(134)},\n",
       " {'sim': tensor(0.1387, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(903),\n",
       "  'idx_1': tensor(3245)},\n",
       " {'sim': tensor(0.2520, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2744),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.2334, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2872),\n",
       "  'idx_1': tensor(2937)},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2111),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.2354, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2111),\n",
       "  'idx_1': tensor(2101)},\n",
       " {'sim': tensor(0.2158, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1015),\n",
       "  'idx_1': tensor(948)},\n",
       " {'sim': tensor(0.2275, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2111),\n",
       "  'idx_1': tensor(3897)},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1015),\n",
       "  'idx_1': tensor(3766)},\n",
       " {'sim': tensor(0.3281, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1699),\n",
       "  'idx_1': tensor(292)},\n",
       " {'sim': tensor(0.2715, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1699),\n",
       "  'idx_1': tensor(356)},\n",
       " {'sim': tensor(0.3672, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4073),\n",
       "  'idx_1': tensor(1898)},\n",
       " {'sim': tensor(0.3574, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4068),\n",
       "  'idx_1': tensor(3684)},\n",
       " {'sim': tensor(0.3320, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(951),\n",
       "  'idx_1': tensor(3960)},\n",
       " {'sim': tensor(0.4102, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4073),\n",
       "  'idx_1': tensor(3113)},\n",
       " {'sim': tensor(0.4512, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2111),\n",
       "  'idx_1': tensor(1981)},\n",
       " {'sim': tensor(0.5156, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2219),\n",
       "  'idx_1': tensor(939)},\n",
       " {'sim': tensor(0.6406, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(951),\n",
       "  'idx_1': tensor(1403)},\n",
       " {'sim': tensor(0.6641, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(951),\n",
       "  'idx_1': tensor(3322)},\n",
       " {'sim': tensor(0.7578, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2744),\n",
       "  'idx_1': tensor(2807)},\n",
       " {'sim': tensor(0.7344, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2872),\n",
       "  'idx_1': tensor(4086)},\n",
       " {'sim': tensor(0.6914, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2872),\n",
       "  'idx_1': tensor(1913)},\n",
       " {'sim': tensor(0.6289, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2872),\n",
       "  'idx_1': tensor(3446)},\n",
       " {'sim': tensor(0.6250, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(951),\n",
       "  'idx_1': tensor(1151)},\n",
       " {'sim': tensor(0.5625, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2872),\n",
       "  'idx_1': tensor(1789)},\n",
       " {'sim': tensor(0.4941, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2872),\n",
       "  'idx_1': tensor(1078)},\n",
       " {'sim': tensor(0.5078, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2219),\n",
       "  'idx_1': tensor(3755)},\n",
       " {'sim': tensor(0.4355, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(695),\n",
       "  'idx_1': tensor(3894)},\n",
       " {'sim': tensor(0.4590, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2283),\n",
       "  'idx_1': tensor(1259)},\n",
       " {'sim': tensor(0.3594, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(810),\n",
       "  'idx_1': tensor(1130)},\n",
       " {'sim': tensor(0.4277, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2283),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.0884, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4032),\n",
       "  'idx_1': tensor(485)},\n",
       " {'sim': tensor(0.1309, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4032),\n",
       "  'idx_1': tensor(64)},\n",
       " {'sim': tensor(0.2715, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3958),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.2432, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3958),\n",
       "  'idx_1': tensor(2937)},\n",
       " {'sim': tensor(0.2383, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3766),\n",
       "  'idx_1': tensor(947)},\n",
       " {'sim': tensor(0.2402, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1971),\n",
       "  'idx_1': tensor(117)},\n",
       " {'sim': tensor(0.2373, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3894),\n",
       "  'idx_1': tensor(820)},\n",
       " {'sim': tensor(0.2461, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3766),\n",
       "  'idx_1': tensor(2613)},\n",
       " {'sim': tensor(0.2754, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3766),\n",
       "  'idx_1': tensor(3766)},\n",
       " {'sim': tensor(0.3164, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(36),\n",
       "  'idx_1': tensor(292)},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(612),\n",
       "  'idx_1': tensor(292)},\n",
       " {'sim': tensor(0.3652, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(228),\n",
       "  'idx_1': tensor(1828)},\n",
       " {'sim': tensor(0.3301, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2148),\n",
       "  'idx_1': tensor(3684)},\n",
       " {'sim': tensor(0.3398, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1387),\n",
       "  'idx_1': tensor(683)},\n",
       " {'sim': tensor(0.4453, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(228),\n",
       "  'idx_1': tensor(2404)},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(170),\n",
       "  'idx_1': tensor(938)},\n",
       " {'sim': tensor(0.5078, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(106),\n",
       "  'idx_1': tensor(2922)},\n",
       " {'sim': tensor(0.5273, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(106),\n",
       "  'idx_1': tensor(3370)},\n",
       " {'sim': tensor(0.5625, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4086),\n",
       "  'idx_1': tensor(1213)},\n",
       " {'sim': tensor(0.7266, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3702),\n",
       "  'idx_1': tensor(2807)},\n",
       " {'sim': tensor(0.7344, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4086),\n",
       "  'idx_1': tensor(2872)},\n",
       " {'sim': tensor(0.8633, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3830),\n",
       "  'idx_1': tensor(1657)},\n",
       " {'sim': tensor(0.8008, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3958),\n",
       "  'idx_1': tensor(3190)},\n",
       " {'sim': tensor(0.7266, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3958),\n",
       "  'idx_1': tensor(116)},\n",
       " {'sim': tensor(0.6719, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3958),\n",
       "  'idx_1': tensor(1661)},\n",
       " {'sim': tensor(0.5547, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3958),\n",
       "  'idx_1': tensor(1078)},\n",
       " {'sim': tensor(0.5039, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2239),\n",
       "  'idx_1': tensor(3065)},\n",
       " {'sim': tensor(0.4922, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3454),\n",
       "  'idx_1': tensor(2805)},\n",
       " {'sim': tensor(0.3789, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3454),\n",
       "  'idx_1': tensor(3637)},\n",
       " {'sim': tensor(0.4648, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1387),\n",
       "  'idx_1': tensor(363)},\n",
       " {'sim': tensor(0.3438, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(298),\n",
       "  'idx_1': tensor(3755)},\n",
       " {'sim': tensor(0.0903, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(371),\n",
       "  'idx_1': tensor(3648)},\n",
       " {'sim': tensor(0.1157, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1593),\n",
       "  'idx_1': tensor(2615)},\n",
       " {'sim': tensor(0.2402, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1913),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.2354, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(61),\n",
       "  'idx_1': tensor(2937)},\n",
       " {'sim': tensor(0.2285, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3326),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.2383, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1593),\n",
       "  'idx_1': tensor(2357)},\n",
       " {'sim': tensor(0.2266, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1721),\n",
       "  'idx_1': tensor(948)},\n",
       " {'sim': tensor(0.2207, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3326),\n",
       "  'idx_1': tensor(3897)},\n",
       " {'sim': tensor(0.2412, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(418),\n",
       "  'idx_1': tensor(2787)},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(42),\n",
       "  'idx_1': tensor(365)},\n",
       " {'sim': tensor(0.2207, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2941),\n",
       "  'idx_1': tensor(755)},\n",
       " {'sim': tensor(0.2988, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(874),\n",
       "  'idx_1': tensor(1834)},\n",
       " {'sim': tensor(0.3145, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(418),\n",
       "  'idx_1': tensor(865)},\n",
       " {'sim': tensor(0.3477, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(426),\n",
       "  'idx_1': tensor(683)},\n",
       " {'sim': tensor(0.4141, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(170),\n",
       "  'idx_1': tensor(2410)},\n",
       " {'sim': tensor(0.4492, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(810),\n",
       "  'idx_1': tensor(938)},\n",
       " {'sim': tensor(0.4961, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(810),\n",
       "  'idx_1': tensor(2858)},\n",
       " {'sim': tensor(0.5469, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(874),\n",
       "  'idx_1': tensor(3370)},\n",
       " {'sim': tensor(0.5312, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(874),\n",
       "  'idx_1': tensor(2858)},\n",
       " {'sim': tensor(0.6602, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1913),\n",
       "  'idx_1': tensor(2807)},\n",
       " {'sim': tensor(0.6914, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1913),\n",
       "  'idx_1': tensor(2872)},\n",
       " {'sim': tensor(0.8633, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1657),\n",
       "  'idx_1': tensor(3830)},\n",
       " {'sim': tensor(0.8359, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1657),\n",
       "  'idx_1': tensor(3190)},\n",
       " {'sim': tensor(0.7930, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3454),\n",
       "  'idx_1': tensor(1151)},\n",
       " {'sim': tensor(0.7227, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3454),\n",
       "  'idx_1': tensor(2293)},\n",
       " {'sim': tensor(0.6719, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3454),\n",
       "  'idx_1': tensor(2805)},\n",
       " {'sim': tensor(0.6094, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3454),\n",
       "  'idx_1': tensor(3065)},\n",
       " {'sim': tensor(0.5664, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(874),\n",
       "  'idx_1': tensor(2346)},\n",
       " {'sim': tensor(0.4004, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3454),\n",
       "  'idx_1': tensor(315)},\n",
       " {'sim': tensor(0.4219, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(874),\n",
       "  'idx_1': tensor(1066)},\n",
       " {'sim': tensor(0.3789, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(554),\n",
       "  'idx_1': tensor(3755)},\n",
       " {'sim': tensor(0.1084, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(309),\n",
       "  'idx_1': tensor(3116)},\n",
       " {'sim': tensor(0.1426, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3051),\n",
       "  'idx_1': tensor(2800)},\n",
       " {'sim': tensor(0.2617, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2549),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.2490, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4025),\n",
       "  'idx_1': tensor(2681)},\n",
       " {'sim': tensor(0.2441, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(373),\n",
       "  'idx_1': tensor(2101)},\n",
       " {'sim': tensor(0.2539, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(373),\n",
       "  'idx_1': tensor(117)},\n",
       " {'sim': tensor(0.2266, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3126),\n",
       "  'idx_1': tensor(820)},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(309),\n",
       "  'idx_1': tensor(2613)},\n",
       " {'sim': tensor(0.2949, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(309),\n",
       "  'idx_1': tensor(4022)},\n",
       " {'sim': tensor(0.3398, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1642),\n",
       "  'idx_1': tensor(3436)},\n",
       " {'sim': tensor(0.2324, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(437),\n",
       "  'idx_1': tensor(691)},\n",
       " {'sim': tensor(0.3184, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1699),\n",
       "  'idx_1': tensor(1892)},\n",
       " {'sim': tensor(0.3320, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1572),\n",
       "  'idx_1': tensor(3684)},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1962),\n",
       "  'idx_1': tensor(747)},\n",
       " {'sim': tensor(0.4102, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1898),\n",
       "  'idx_1': tensor(2793)},\n",
       " {'sim': tensor(0.4629, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1578),\n",
       "  'idx_1': tensor(938)},\n",
       " {'sim': tensor(0.4922, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1834),\n",
       "  'idx_1': tensor(2858)},\n",
       " {'sim': tensor(0.5547, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1770),\n",
       "  'idx_1': tensor(3370)},\n",
       " {'sim': tensor(0.5000, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1770),\n",
       "  'idx_1': tensor(2858)},\n",
       " {'sim': tensor(0.6250, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(568),\n",
       "  'idx_1': tensor(2935)},\n",
       " {'sim': tensor(0.6289, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3446),\n",
       "  'idx_1': tensor(2872)},\n",
       " {'sim': tensor(0.8008, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3190),\n",
       "  'idx_1': tensor(3958)},\n",
       " {'sim': tensor(0.8359, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3190),\n",
       "  'idx_1': tensor(1657)},\n",
       " {'sim': tensor(0.7891, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(373),\n",
       "  'idx_1': tensor(116)},\n",
       " {'sim': tensor(0.7812, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3769),\n",
       "  'idx_1': tensor(2679)},\n",
       " {'sim': tensor(0.6914, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2739),\n",
       "  'idx_1': tensor(2805)},\n",
       " {'sim': tensor(0.5586, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3446),\n",
       "  'idx_1': tensor(2299)},\n",
       " {'sim': tensor(0.5859, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1642),\n",
       "  'idx_1': tensor(2346)},\n",
       " {'sim': tensor(0.4336, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1642),\n",
       "  'idx_1': tensor(1259)},\n",
       " {'sim': tensor(0.4121, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1770),\n",
       "  'idx_1': tensor(1066)},\n",
       " {'sim': tensor(0.4160, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1642),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.0981, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(448),\n",
       "  'idx_1': tensor(3718)},\n",
       " {'sim': tensor(0.1494, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(448),\n",
       "  'idx_1': tensor(2)},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(244),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.2383, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1151),\n",
       "  'idx_1': tensor(2877)},\n",
       " {'sim': tensor(0.2490, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1151),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.2520, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(116),\n",
       "  'idx_1': tensor(117)},\n",
       " {'sim': tensor(0.2139, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(52),\n",
       "  'idx_1': tensor(820)},\n",
       " {'sim': tensor(0.2373, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1407),\n",
       "  'idx_1': tensor(3897)},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(436),\n",
       "  'idx_1': tensor(3766)},\n",
       " {'sim': tensor(0.3613, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1515),\n",
       "  'idx_1': tensor(3436)},\n",
       " {'sim': tensor(0.2178, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(244),\n",
       "  'idx_1': tensor(755)},\n",
       " {'sim': tensor(0.2812, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(810),\n",
       "  'idx_1': tensor(3755)},\n",
       " {'sim': tensor(0.3125, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(874),\n",
       "  'idx_1': tensor(3626)},\n",
       " {'sim': tensor(0.3535, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(874),\n",
       "  'idx_1': tensor(683)},\n",
       " {'sim': tensor(0.4121, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(874),\n",
       "  'idx_1': tensor(2410)},\n",
       " {'sim': tensor(0.3770, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(810),\n",
       "  'idx_1': tensor(2154)},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1515),\n",
       "  'idx_1': tensor(1003)},\n",
       " {'sim': tensor(0.4785, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(810),\n",
       "  'idx_1': tensor(3434)},\n",
       " {'sim': tensor(0.4941, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1515),\n",
       "  'idx_1': tensor(1515)},\n",
       " {'sim': tensor(0.5391, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(874),\n",
       "  'idx_1': tensor(1258)},\n",
       " {'sim': tensor(0.6250, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1151),\n",
       "  'idx_1': tensor(951)},\n",
       " {'sim': tensor(0.7266, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(116),\n",
       "  'idx_1': tensor(3958)},\n",
       " {'sim': tensor(0.7930, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1151),\n",
       "  'idx_1': tensor(3454)},\n",
       " {'sim': tensor(0.7891, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(116),\n",
       "  'idx_1': tensor(373)},\n",
       " {'sim': tensor(0.8242, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1535),\n",
       "  'idx_1': tensor(1405)},\n",
       " {'sim': tensor(0.7812, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1151),\n",
       "  'idx_1': tensor(2805)},\n",
       " {'sim': tensor(0.6914, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1515),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.5898, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1151),\n",
       "  'idx_1': tensor(3894)},\n",
       " {'sim': tensor(0.6289, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1515),\n",
       "  'idx_1': tensor(1259)},\n",
       " {'sim': tensor(0.4512, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1643),\n",
       "  'idx_1': tensor(427)},\n",
       " {'sim': tensor(0.6211, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1515),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.0928, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2277),\n",
       "  'idx_1': tensor(462)},\n",
       " {'sim': tensor(0.1230, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2229),\n",
       "  'idx_1': tensor(69)},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2237),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.2373, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2237),\n",
       "  'idx_1': tensor(2937)},\n",
       " {'sim': tensor(0.2344, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1405),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.2334, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1661),\n",
       "  'idx_1': tensor(117)},\n",
       " {'sim': tensor(0.2109, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1661),\n",
       "  'idx_1': tensor(3642)},\n",
       " {'sim': tensor(0.2363, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1405),\n",
       "  'idx_1': tensor(3897)},\n",
       " {'sim': tensor(0.2314, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2743),\n",
       "  'idx_1': tensor(3766)},\n",
       " {'sim': tensor(0.2969, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2154),\n",
       "  'idx_1': tensor(365)},\n",
       " {'sim': tensor(0.2432, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1380),\n",
       "  'idx_1': tensor(292)},\n",
       " {'sim': tensor(0.2637, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1380),\n",
       "  'idx_1': tensor(1636)},\n",
       " {'sim': tensor(0.2969, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2154),\n",
       "  'idx_1': tensor(3626)},\n",
       " {'sim': tensor(0.3008, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2154),\n",
       "  'idx_1': tensor(683)},\n",
       " {'sim': tensor(0.3516, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2154),\n",
       "  'idx_1': tensor(2410)},\n",
       " {'sim': tensor(0.3340, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1323),\n",
       "  'idx_1': tensor(235)},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2237),\n",
       "  'idx_1': tensor(59)},\n",
       " {'sim': tensor(0.4199, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2090),\n",
       "  'idx_1': tensor(3434)},\n",
       " {'sim': tensor(0.4590, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2237),\n",
       "  'idx_1': tensor(1277)},\n",
       " {'sim': tensor(0.5078, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2807),\n",
       "  'idx_1': tensor(2935)},\n",
       " {'sim': tensor(0.5625, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1789),\n",
       "  'idx_1': tensor(2872)},\n",
       " {'sim': tensor(0.6719, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1661),\n",
       "  'idx_1': tensor(3958)},\n",
       " {'sim': tensor(0.7227, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2293),\n",
       "  'idx_1': tensor(3454)},\n",
       " {'sim': tensor(0.7812, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2679),\n",
       "  'idx_1': tensor(3769)},\n",
       " {'sim': tensor(0.8242, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1405),\n",
       "  'idx_1': tensor(1535)},\n",
       " {'sim': tensor(0.7930, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2293),\n",
       "  'idx_1': tensor(2805)},\n",
       " {'sim': tensor(0.7070, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2293),\n",
       "  'idx_1': tensor(505)},\n",
       " {'sim': tensor(0.6719, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2679),\n",
       "  'idx_1': tensor(2805)},\n",
       " {'sim': tensor(0.5508, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3500),\n",
       "  'idx_1': tensor(2924)},\n",
       " {'sim': tensor(0.5391, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1387),\n",
       "  'idx_1': tensor(3435)},\n",
       " {'sim': tensor(0.4062, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1387),\n",
       "  'idx_1': tensor(2282)},\n",
       " {'sim': tensor(0.1084, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1600),\n",
       "  'idx_1': tensor(1310)},\n",
       " {'sim': tensor(0.1592, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3968),\n",
       "  'idx_1': tensor(2909)},\n",
       " {'sim': tensor(0.2178, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3385),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.2139, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1854),\n",
       "  'idx_1': tensor(2877)},\n",
       " {'sim': tensor(0.2246, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2805),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.2334, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2805),\n",
       "  'idx_1': tensor(2101)},\n",
       " {'sim': tensor(0.2363, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2741),\n",
       "  'idx_1': tensor(3698)},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1854),\n",
       "  'idx_1': tensor(3897)},\n",
       " {'sim': tensor(0.2178, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(868),\n",
       "  'idx_1': tensor(2723)},\n",
       " {'sim': tensor(0.2949, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1898),\n",
       "  'idx_1': tensor(365)},\n",
       " {'sim': tensor(0.2217, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(802),\n",
       "  'idx_1': tensor(292)},\n",
       " {'sim': tensor(0.2500, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1834),\n",
       "  'idx_1': tensor(3755)},\n",
       " {'sim': tensor(0.2930, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1898),\n",
       "  'idx_1': tensor(3626)},\n",
       " {'sim': tensor(0.3242, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1898),\n",
       "  'idx_1': tensor(683)},\n",
       " {'sim': tensor(0.3379, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1898),\n",
       "  'idx_1': tensor(427)},\n",
       " {'sim': tensor(0.3379, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1834),\n",
       "  'idx_1': tensor(2154)},\n",
       " {'sim': tensor(0.3359, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(812),\n",
       "  'idx_1': tensor(2858)},\n",
       " {'sim': tensor(0.4551, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1834),\n",
       "  'idx_1': tensor(3434)},\n",
       " {'sim': tensor(0.4180, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1834),\n",
       "  'idx_1': tensor(2922)},\n",
       " {'sim': tensor(0.4355, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1898),\n",
       "  'idx_1': tensor(1258)},\n",
       " {'sim': tensor(0.4941, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1078),\n",
       "  'idx_1': tensor(2872)},\n",
       " {'sim': tensor(0.5547, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1078),\n",
       "  'idx_1': tensor(3958)},\n",
       " {'sim': tensor(0.6719, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2805),\n",
       "  'idx_1': tensor(3454)},\n",
       " {'sim': tensor(0.6914, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2805),\n",
       "  'idx_1': tensor(2739)},\n",
       " {'sim': tensor(0.7812, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2805),\n",
       "  'idx_1': tensor(1151)},\n",
       " {'sim': tensor(0.7930, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2805),\n",
       "  'idx_1': tensor(2293)},\n",
       " {'sim': tensor(0.7578, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(828),\n",
       "  'idx_1': tensor(3836)},\n",
       " {'sim': tensor(0.6836, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3902),\n",
       "  'idx_1': tensor(3894)},\n",
       " {'sim': tensor(0.5781, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(876),\n",
       "  'idx_1': tensor(2860)},\n",
       " {'sim': tensor(0.4961, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1898),\n",
       "  'idx_1': tensor(363)},\n",
       " {'sim': tensor(0.4629, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(812),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.1108, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(256),\n",
       "  'idx_1': tensor(1809)},\n",
       " {'sim': tensor(0.1445, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1443),\n",
       "  'idx_1': tensor(1200)},\n",
       " {'sim': tensor(0.1963, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1401),\n",
       "  'idx_1': tensor(947)},\n",
       " {'sim': tensor(0.1924, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2809),\n",
       "  'idx_1': tensor(2877)},\n",
       " {'sim': tensor(0.2119, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2809),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1401),\n",
       "  'idx_1': tensor(2101)},\n",
       " {'sim': tensor(0.1943, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1401),\n",
       "  'idx_1': tensor(820)},\n",
       " {'sim': tensor(0.2021, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2809),\n",
       "  'idx_1': tensor(3897)},\n",
       " {'sim': tensor(0.2012, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(948),\n",
       "  'idx_1': tensor(4022)},\n",
       " {'sim': tensor(0.3398, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(3436)},\n",
       " {'sim': tensor(0.2021, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3491),\n",
       "  'idx_1': tensor(356)},\n",
       " {'sim': tensor(0.2266, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3813),\n",
       "  'idx_1': tensor(1572)},\n",
       " {'sim': tensor(0.2812, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(1003)},\n",
       " {'sim': tensor(0.2891, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3755),\n",
       "  'idx_1': tensor(747)},\n",
       " {'sim': tensor(0.3906, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3755),\n",
       "  'idx_1': tensor(491)},\n",
       " {'sim': tensor(0.3105, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(2218)},\n",
       " {'sim': tensor(0.3945, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(1003)},\n",
       " {'sim': tensor(0.3926, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(3370)},\n",
       " {'sim': tensor(0.4434, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3755),\n",
       "  'idx_1': tensor(1451)},\n",
       " {'sim': tensor(0.3828, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3065),\n",
       "  'idx_1': tensor(53)},\n",
       " {'sim': tensor(0.5078, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3755),\n",
       "  'idx_1': tensor(2219)},\n",
       " {'sim': tensor(0.5039, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3065),\n",
       "  'idx_1': tensor(2239)},\n",
       " {'sim': tensor(0.6094, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3065),\n",
       "  'idx_1': tensor(3454)},\n",
       " {'sim': tensor(0.5586, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2299),\n",
       "  'idx_1': tensor(3446)},\n",
       " {'sim': tensor(0.6914, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(1515)},\n",
       " {'sim': tensor(0.7070, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(505),\n",
       "  'idx_1': tensor(2293)},\n",
       " {'sim': tensor(0.7578, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3836),\n",
       "  'idx_1': tensor(828)},\n",
       " {'sim': tensor(0.8164, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1209),\n",
       "  'idx_1': tensor(3894)},\n",
       " {'sim': tensor(0.6641, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1209),\n",
       "  'idx_1': tensor(315)},\n",
       " {'sim': tensor(0.4961, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3563),\n",
       "  'idx_1': tensor(299)},\n",
       " {'sim': tensor(0.6367, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.0928, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3840),\n",
       "  'idx_1': tensor(3770)},\n",
       " {'sim': tensor(0.1221, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3840),\n",
       "  'idx_1': tensor(1027)},\n",
       " {'sim': tensor(0.2002, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1662),\n",
       "  'idx_1': tensor(1207)},\n",
       " {'sim': tensor(0.1992, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1662),\n",
       "  'idx_1': tensor(2937)},\n",
       " {'sim': tensor(0.2100, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3894),\n",
       "  'idx_1': tensor(2678)},\n",
       " {'sim': tensor(0.2148, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4003),\n",
       "  'idx_1': tensor(743)},\n",
       " {'sim': tensor(0.1807, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3894),\n",
       "  'idx_1': tensor(120)},\n",
       " {'sim': tensor(0.1973, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4003),\n",
       "  'idx_1': tensor(2274)},\n",
       " {'sim': tensor(0.3262, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3840),\n",
       "  'idx_1': tensor(4032)},\n",
       " {'sim': tensor(0.2734, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3308),\n",
       "  'idx_1': tensor(301)},\n",
       " {'sim': tensor(0.2432, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2020),\n",
       "  'idx_1': tensor(292)},\n",
       " {'sim': tensor(0.2910, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1956),\n",
       "  'idx_1': tensor(1572)},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4003),\n",
       "  'idx_1': tensor(865)},\n",
       " {'sim': tensor(0.2793, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2027),\n",
       "  'idx_1': tensor(683)},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2027),\n",
       "  'idx_1': tensor(427)},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2346),\n",
       "  'idx_1': tensor(1002)},\n",
       " {'sim': tensor(0.3594, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2346),\n",
       "  'idx_1': tensor(2922)},\n",
       " {'sim': tensor(0.4746, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2346),\n",
       "  'idx_1': tensor(3370)},\n",
       " {'sim': tensor(0.4043, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1963),\n",
       "  'idx_1': tensor(1835)},\n",
       " {'sim': tensor(0.4199, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1599),\n",
       "  'idx_1': tensor(2427)},\n",
       " {'sim': tensor(0.4355, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3894),\n",
       "  'idx_1': tensor(695)},\n",
       " {'sim': tensor(0.4922, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2805),\n",
       "  'idx_1': tensor(3454)},\n",
       " {'sim': tensor(0.5664, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2346),\n",
       "  'idx_1': tensor(874)},\n",
       " {'sim': tensor(0.5859, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2346),\n",
       "  'idx_1': tensor(1642)},\n",
       " {'sim': tensor(0.5898, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3894),\n",
       "  'idx_1': tensor(1151)},\n",
       " {'sim': tensor(0.6719, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2805),\n",
       "  'idx_1': tensor(2679)},\n",
       " {'sim': tensor(0.6836, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3894),\n",
       "  'idx_1': tensor(3902)},\n",
       " {'sim': tensor(0.8164, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3894),\n",
       "  'idx_1': tensor(1209)},\n",
       " {'sim': tensor(0.7461, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3894),\n",
       "  'idx_1': tensor(315)},\n",
       " {'sim': tensor(0.5898, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3308),\n",
       "  'idx_1': tensor(363)},\n",
       " {'sim': tensor(0.5352, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4076),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.0967, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(851),\n",
       "  'idx_1': tensor(74)},\n",
       " {'sim': tensor(0.1699, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(797),\n",
       "  'idx_1': tensor(1446)},\n",
       " {'sim': tensor(0.1914, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(804),\n",
       "  'idx_1': tensor(3066)},\n",
       " {'sim': tensor(0.1816, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(550),\n",
       "  'idx_1': tensor(3429)},\n",
       " {'sim': tensor(0.1758, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(354),\n",
       "  'idx_1': tensor(1572)},\n",
       " {'sim': tensor(0.2100, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2851),\n",
       "  'idx_1': tensor(1830)},\n",
       " {'sim': tensor(0.1670, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1824),\n",
       "  'idx_1': tensor(478)},\n",
       " {'sim': tensor(0.2012, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1824),\n",
       "  'idx_1': tensor(2787)},\n",
       " {'sim': tensor(0.2305, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(354),\n",
       "  'idx_1': tensor(2787)},\n",
       " {'sim': tensor(0.3047, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1387),\n",
       "  'idx_1': tensor(3436)},\n",
       " {'sim': tensor(0.2773, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2851),\n",
       "  'idx_1': tensor(356)},\n",
       " {'sim': tensor(0.2559, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1828),\n",
       "  'idx_1': tensor(1572)},\n",
       " {'sim': tensor(0.2871, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1387),\n",
       "  'idx_1': tensor(1003)},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1195),\n",
       "  'idx_1': tensor(747)},\n",
       " {'sim': tensor(0.3438, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1195),\n",
       "  'idx_1': tensor(491)},\n",
       " {'sim': tensor(0.2949, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1259),\n",
       "  'idx_1': tensor(2218)},\n",
       " {'sim': tensor(0.3555, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1259),\n",
       "  'idx_1': tensor(1003)},\n",
       " {'sim': tensor(0.4570, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2851),\n",
       "  'idx_1': tensor(3171)},\n",
       " {'sim': tensor(0.4336, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1259),\n",
       "  'idx_1': tensor(1515)},\n",
       " {'sim': tensor(0.3672, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2851),\n",
       "  'idx_1': tensor(2212)},\n",
       " {'sim': tensor(0.4590, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1259),\n",
       "  'idx_1': tensor(2283)},\n",
       " {'sim': tensor(0.3789, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3637),\n",
       "  'idx_1': tensor(3454)},\n",
       " {'sim': tensor(0.4004, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(315),\n",
       "  'idx_1': tensor(3454)},\n",
       " {'sim': tensor(0.4336, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1259),\n",
       "  'idx_1': tensor(1642)},\n",
       " {'sim': tensor(0.6289, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1259),\n",
       "  'idx_1': tensor(1515)},\n",
       " {'sim': tensor(0.5508, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2924),\n",
       "  'idx_1': tensor(3500)},\n",
       " {'sim': tensor(0.5781, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2860),\n",
       "  'idx_1': tensor(876)},\n",
       " {'sim': tensor(0.6641, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(315),\n",
       "  'idx_1': tensor(1209)},\n",
       " {'sim': tensor(0.7461, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(315),\n",
       "  'idx_1': tensor(3894)},\n",
       " {'sim': tensor(0.7227, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(315),\n",
       "  'idx_1': tensor(3829)},\n",
       " {'sim': tensor(0.6641, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1387),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.0942, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2908),\n",
       "  'idx_1': tensor(412)},\n",
       " {'sim': tensor(0.1074, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(4020),\n",
       "  'idx_1': tensor(1256)},\n",
       " {'sim': tensor(0.1309, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3000),\n",
       "  'idx_1': tensor(953)},\n",
       " {'sim': tensor(0.1445, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3064),\n",
       "  'idx_1': tensor(2930)},\n",
       " {'sim': tensor(0.1797, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(417),\n",
       "  'idx_1': tensor(1572)},\n",
       " {'sim': tensor(0.1895, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3425),\n",
       "  'idx_1': tensor(675)},\n",
       " {'sim': tensor(0.1641, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3414),\n",
       "  'idx_1': tensor(473)},\n",
       " {'sim': tensor(0.1816, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3637),\n",
       "  'idx_1': tensor(3955)},\n",
       " {'sim': tensor(0.2363, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3425),\n",
       "  'idx_1': tensor(2787)},\n",
       " {'sim': tensor(0.2598, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(363),\n",
       "  'idx_1': tensor(3692)},\n",
       " {'sim': tensor(0.2129, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3425),\n",
       "  'idx_1': tensor(292)},\n",
       " {'sim': tensor(0.2734, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3425),\n",
       "  'idx_1': tensor(1636)},\n",
       " {'sim': tensor(0.2832, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3425),\n",
       "  'idx_1': tensor(3680)},\n",
       " {'sim': tensor(0.3145, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(363),\n",
       "  'idx_1': tensor(683)},\n",
       " {'sim': tensor(0.3418, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(363),\n",
       "  'idx_1': tensor(427)},\n",
       " {'sim': tensor(0.2832, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(299),\n",
       "  'idx_1': tensor(235)},\n",
       " {'sim': tensor(0.2930, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1066),\n",
       "  'idx_1': tensor(2922)},\n",
       " {'sim': tensor(0.3770, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(299),\n",
       "  'idx_1': tensor(3434)},\n",
       " {'sim': tensor(0.3965, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(427),\n",
       "  'idx_1': tensor(1835)},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3414),\n",
       "  'idx_1': tensor(1107)},\n",
       " {'sim': tensor(0.3594, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1130),\n",
       "  'idx_1': tensor(810)},\n",
       " {'sim': tensor(0.4648, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(363),\n",
       "  'idx_1': tensor(1387)},\n",
       " {'sim': tensor(0.4219, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1066),\n",
       "  'idx_1': tensor(874)},\n",
       " {'sim': tensor(0.4121, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(1066),\n",
       "  'idx_1': tensor(1770)},\n",
       " {'sim': tensor(0.4512, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(427),\n",
       "  'idx_1': tensor(1643)},\n",
       " {'sim': tensor(0.5391, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3435),\n",
       "  'idx_1': tensor(1387)},\n",
       " {'sim': tensor(0.4961, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(363),\n",
       "  'idx_1': tensor(1898)},\n",
       " {'sim': tensor(0.4961, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(299),\n",
       "  'idx_1': tensor(3563)},\n",
       " {'sim': tensor(0.5898, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(363),\n",
       "  'idx_1': tensor(3308)},\n",
       " {'sim': tensor(0.7227, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2872),\n",
       "  'idx_1': tensor(3002)},\n",
       " {'sim': tensor(0.8008, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3327),\n",
       "  'idx_1': tensor(2616)},\n",
       " {'sim': tensor(0.0933, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3542),\n",
       "  'idx_1': tensor(2617)},\n",
       " {'sim': tensor(0.0986, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(661),\n",
       "  'idx_1': tensor(860)},\n",
       " {'sim': tensor(0.1108, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2825),\n",
       "  'idx_1': tensor(3463)},\n",
       " {'sim': tensor(0.1289, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3115),\n",
       "  'idx_1': tensor(2036)},\n",
       " {'sim': tensor(0.1748, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2465),\n",
       "  'idx_1': tensor(1572)},\n",
       " {'sim': tensor(0.2012, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2460),\n",
       "  'idx_1': tensor(1820)},\n",
       " {'sim': tensor(0.1729, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2460),\n",
       "  'idx_1': tensor(3803)},\n",
       " {'sim': tensor(0.2158, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3809),\n",
       "  'idx_1': tensor(2787)},\n",
       " {'sim': tensor(0.2041, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2465),\n",
       "  'idx_1': tensor(2787)},\n",
       " {'sim': tensor(0.3164, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(3308)},\n",
       " {'sim': tensor(0.1865, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2743),\n",
       "  'idx_1': tensor(2363)},\n",
       " {'sim': tensor(0.2168, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2465),\n",
       "  'idx_1': tensor(2656)},\n",
       " {'sim': tensor(0.2695, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(1003)},\n",
       " {'sim': tensor(0.2480, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3755),\n",
       "  'idx_1': tensor(1003)},\n",
       " {'sim': tensor(0.3438, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3755),\n",
       "  'idx_1': tensor(491)},\n",
       " {'sim': tensor(0.2852, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(171)},\n",
       " {'sim': tensor(0.3496, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(1003)},\n",
       " {'sim': tensor(0.4043, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(3370)},\n",
       " {'sim': tensor(0.4473, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(1515)},\n",
       " {'sim': tensor(0.3516, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2454),\n",
       "  'idx_1': tensor(2263)},\n",
       " {'sim': tensor(0.4277, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(2283)},\n",
       " {'sim': tensor(0.3438, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3755),\n",
       "  'idx_1': tensor(298)},\n",
       " {'sim': tensor(0.3789, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3755),\n",
       "  'idx_1': tensor(554)},\n",
       " {'sim': tensor(0.4160, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(1642)},\n",
       " {'sim': tensor(0.6211, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(1515)},\n",
       " {'sim': tensor(0.4062, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2282),\n",
       "  'idx_1': tensor(1387)},\n",
       " {'sim': tensor(0.4629, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(812)},\n",
       " {'sim': tensor(0.6367, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(3819)},\n",
       " {'sim': tensor(0.5352, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(4076)},\n",
       " {'sim': tensor(0.6641, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(3819),\n",
       "  'idx_1': tensor(1387)},\n",
       " {'sim': tensor(0.8008, dtype=torch.bfloat16),\n",
       "  'idx_0': tensor(2616),\n",
       "  'idx_1': tensor(3327)}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import pairwise_cosine_similarity\n",
    "\n",
    "pairwise_cosine_similarity(\n",
    "    model.state_dict()[\"model.layers.0.self_attn.q_proj.weight\"],\n",
    "    model.state_dict()[\"model.layers.1.self_attn.q_proj.weight\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "cos = nn.CosineSimilarity(dim = 0, eps=1e-6)\n",
    "output = cos(\n",
    "    model.state_dict()[\"model.layers.0.self_attn.q_proj.weight\"],\n",
    "    model.state_dict()[\"model.layers.1.self_attn.q_proj.weight\"]\n",
    ")\n",
    "output[torch.argmax(output)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()[\"model.layers.0.self_attn.q_proj.weight\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import CosineSimilarity\n",
    "\n",
    "cosine_similarity = CosineSimilarity(reduction = 'mean')\n",
    "cosine_similarity(\n",
    "    model.state_dict()[\"model.layers.0.self_attn.q_proj.weight\"],\n",
    "    model.state_dict()[\"model.layers.1.self_attn.q_proj.weight\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(\n",
    "    model.state_dict()[\"model.layers.0.self_attn.q_proj.weight\"],\n",
    "    model.state_dict()[\"model.layers.7.self_attn.q_proj.weight\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmin-WyFAvJN6-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
